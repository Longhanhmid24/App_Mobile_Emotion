{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d488171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Input\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77c7837d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ng dn\n",
    "train_dir = 'D:/DatasetDoAnCoSO/dataset_emotion/images/train'\n",
    "val_dir = 'D:/DatasetDoAnCoSO/dataset_emotion/images/validation'\n",
    "\n",
    "# Ly danh sch lp\n",
    "classes = os.listdir(train_dir)\n",
    "train_counts = []\n",
    "val_counts = []\n",
    "\n",
    "# m nh\n",
    "for cls in classes:\n",
    "    train_path = os.path.join(train_dir, cls)\n",
    "    val_path = os.path.join(val_dir, cls)\n",
    "\n",
    "    train_count = len(os.listdir(train_path)) if os.path.exists(train_path) else 0\n",
    "    val_count = len(os.listdir(val_path)) if os.path.exists(val_path) else 0\n",
    "\n",
    "    train_counts.append(train_count)\n",
    "    val_counts.append(val_count)\n",
    "\n",
    "# V biu \n",
    "x = np.arange(len(classes))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "rects1 = ax.bar(x - width/2, train_counts, width, label='Train')\n",
    "rects2 = ax.bar(x + width/2, val_counts, width, label='Validation')\n",
    "\n",
    "ax.set_ylabel('S lng nh')\n",
    "ax.set_xlabel('Lp cm xc')\n",
    "ax.set_title('S lng nh theo tng lp (Train vs Validation)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(classes, rotation=15)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Hin th s lng trn u mi ct\n",
    "for rects in [rects1, rects2]:\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 im pixel ln trn\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "821acc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 images belonging to 7 classes.\n",
      "Found 7066 images belonging to 7 classes.\n",
      "File generator_info.json  c to!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# ng dn\n",
    "train_dir = 'D:/DatasetDoAnCoSO/dataset_emotion/images/train'\n",
    "val_dir = 'D:/DatasetDoAnCoSO/dataset_emotion/images/validation'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale = 1.0/255.0,\n",
    "        width_shift_range = 0.1,\n",
    "        height_shift_range = 0.1,\n",
    "        rotation_range = 20,\n",
    "        horizontal_flip = True\n",
    "    )\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale= 1.0/255\n",
    ")\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(56,56),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(56,56),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "# Lu thng tin v generator vo file JSON\n",
    "generator_part2 = {\n",
    "    \"train_generator\": {\n",
    "        \"target_size\": train_generator.target_size,\n",
    "        \"color_mode\": train_generator.color_mode,\n",
    "        \"batch_size\": train_generator.batch_size,\n",
    "        \"class_mode\": train_generator.class_mode,\n",
    "        \"num_classes\": len(train_generator.class_indices),\n",
    "        \"class_labels\": list(train_generator.class_indices.keys())\n",
    "    },\n",
    "    \"validation_generator\": {\n",
    "        \"target_size\": validation_generator.target_size,\n",
    "        \"color_mode\": validation_generator.color_mode,\n",
    "        \"batch_size\": validation_generator.batch_size,\n",
    "        \"class_mode\": validation_generator.class_mode,\n",
    "        \"num_classes\": len(validation_generator.class_indices),\n",
    "        \"class_labels\": list(validation_generator.class_indices.keys())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Lu vo file JSON\n",
    "with open('generator_part2.json', 'w') as json_file:\n",
    "    json.dump(generator_part2, json_file, indent=4)\n",
    "\n",
    "print(\"File generator_info.json  c to!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b5aadc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73132a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> \n",
       "\n",
       " batch_normalization              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> \n",
       "\n",
       " batch_normalization_1            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">590,336</span> \n",
       "\n",
       " batch_normalization_2            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> \n",
       "\n",
       " batch_normalization_3            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> \n",
       "\n",
       " batch_normalization_4            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> \n",
       "\n",
       " batch_normalization_5            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,591</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " conv2d (\u001b[38;5;33mConv2D\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)                \u001b[38;5;34m640\u001b[0m \n",
       "\n",
       " batch_normalization              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)                \u001b[38;5;34m256\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " activation (\u001b[38;5;33mActivation\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)           \u001b[38;5;34m204,928\u001b[0m \n",
       "\n",
       " batch_normalization_1            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)               \u001b[38;5;34m512\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " activation_1 (\u001b[38;5;33mActivation\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)           \u001b[38;5;34m590,336\u001b[0m \n",
       "\n",
       " batch_normalization_2            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)             \u001b[38;5;34m2,048\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " activation_2 (\u001b[38;5;33mActivation\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_2 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           \u001b[38;5;34m2,359,808\u001b[0m \n",
       "\n",
       " batch_normalization_3            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)               \u001b[38;5;34m2,048\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " activation_3 (\u001b[38;5;33mActivation\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_3 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " flatten (\u001b[38;5;33mFlatten\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)                        \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 \u001b[38;5;34m1,179,904\u001b[0m \n",
       "\n",
       " batch_normalization_4            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                     \u001b[38;5;34m1,024\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " activation_4 (\u001b[38;5;33mActivation\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_4 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                   \u001b[38;5;34m131,584\u001b[0m \n",
       "\n",
       " batch_normalization_5            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                     \u001b[38;5;34m2,048\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " activation_5 (\u001b[38;5;33mActivation\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_5 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_2 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                       \u001b[38;5;34m3,591\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,478,727</span> (17.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,478,727\u001b[0m (17.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,474,759</span> (17.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,474,759\u001b[0m (17.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,968</span> (15.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,968\u001b[0m (15.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Khi to m hnh mng n-ron tch chp (CNN)\n",
    "model = Sequential()\n",
    "\n",
    "# 1 - Lp tch chp u tin\n",
    "model.add(Conv2D(64, (3,3), padding='same', input_shape=(56, 56, 1)))  # Lp tch chp vi 64 b lc kch thc 3x3\n",
    "model.add(BatchNormalization())  # Chun ha d liu u ra ca lp tch chp\n",
    "model.add(Activation('relu'))    # p dng hm kch hot ReLU\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # Lp ly mu cc i 2x2\n",
    "model.add(Dropout(0.25))  # Ngu nhin b 25% s lng n-ron  trnh hin tng qu khp\n",
    "\n",
    "# 2 - Lp tch chp th hai\n",
    "model.add(Conv2D(128, (5,5), padding='same'))  # 128 b lc kch thc 5x5\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 3 - Lp tch chp th ba\n",
    "model.add(Conv2D(512, (3,3), padding='same'))  # 512 b lc kch thc 3x3\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 4 - Lp tch chp th t\n",
    "model.add(Conv2D(512, (3,3), padding='same'))  # 512 b lc kch thc 3x3\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Chuyn t d liu 2 chiu sang 1 chiu (lm phng)\n",
    "model.add(Flatten())\n",
    "\n",
    "# 5 - Lp Fully Connected th nht\n",
    "model.add(Dense(256))  # Lp kt ni vi 256 n-ron\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 6 - Lp Fully Connected th hai\n",
    "model.add(Dense(512))  # Lp kt ni vi 512 n-ron\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 7 - Lp Input \n",
    "model.add(Dense(7, activation='softmax'))  # 7 u ra ng vi 7 cm xc, dng hm kch hot softmax  phn loi\n",
    "\n",
    "# In ra tm tt m hnh\n",
    "print(model.summary())\n",
    "\n",
    "# Khi to b ti u ha Adam vi tc  hc nh\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "\n",
    "# Bin dch m hnh, xc nh thut ton ti u, hm mt mt v ch s nh gi\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb82e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.2088 - loss: 2.0713\n",
      "Epoch 1: val_accuracy improved from -inf to 0.29730, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m481s\u001b[0m 265ms/step - accuracy: 0.2088 - loss: 2.0713 - val_accuracy: 0.2973 - val_loss: 1.7316\n",
      "Epoch 2/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:12\u001b[0m 174ms/step - accuracy: 0.1875 - loss: 1.9280"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_accuracy improved from 0.29730 to 0.29773, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.1875 - loss: 1.9280 - val_accuracy: 0.2977 - val_loss: 1.7318\n",
      "Epoch 3/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.2505 - loss: 1.8747\n",
      "Epoch 3: val_accuracy improved from 0.29773 to 0.35696, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 187ms/step - accuracy: 0.2506 - loss: 1.8747 - val_accuracy: 0.3570 - val_loss: 1.6246\n",
      "Epoch 4/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m4:55\u001b[0m 164ms/step - accuracy: 0.1875 - loss: 2.0213\n",
      "Epoch 4: val_accuracy improved from 0.35696 to 0.35795, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.1875 - loss: 2.0213 - val_accuracy: 0.3580 - val_loss: 1.6237\n",
      "Epoch 5/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.3125 - loss: 1.7485\n",
      "Epoch 5: val_accuracy did not improve from 0.35795\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 207ms/step - accuracy: 0.3125 - loss: 1.7485 - val_accuracy: 0.2625 - val_loss: 1.9773\n",
      "Epoch 6/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:28\u001b[0m 182ms/step - accuracy: 0.1875 - loss: 1.7168\n",
      "Epoch 6: val_accuracy did not improve from 0.35795\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.1875 - loss: 1.7168 - val_accuracy: 0.2635 - val_loss: 1.9676\n",
      "Epoch 7/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.3490 - loss: 1.6594\n",
      "Epoch 7: val_accuracy did not improve from 0.35795\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 186ms/step - accuracy: 0.3490 - loss: 1.6594 - val_accuracy: 0.3520 - val_loss: 1.7434\n",
      "Epoch 8/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m4:47\u001b[0m 160ms/step - accuracy: 0.1875 - loss: 2.1272\n",
      "Epoch 8: val_accuracy improved from 0.35795 to 0.35938, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.1875 - loss: 2.1272 - val_accuracy: 0.3594 - val_loss: 1.7163\n",
      "Epoch 9/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.3933 - loss: 1.5619\n",
      "Epoch 9: val_accuracy improved from 0.35938 to 0.50099, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 183ms/step - accuracy: 0.3933 - loss: 1.5619 - val_accuracy: 0.5010 - val_loss: 1.3103\n",
      "Epoch 10/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:07\u001b[0m 171ms/step - accuracy: 0.6875 - loss: 1.0624\n",
      "Epoch 10: val_accuracy did not improve from 0.50099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 1.0624 - val_accuracy: 0.4996 - val_loss: 1.3097\n",
      "Epoch 11/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.4186 - loss: 1.4951\n",
      "Epoch 11: val_accuracy did not improve from 0.50099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 182ms/step - accuracy: 0.4186 - loss: 1.4951 - val_accuracy: 0.4766 - val_loss: 1.3941\n",
      "Epoch 12/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:03\u001b[0m 169ms/step - accuracy: 0.3750 - loss: 1.8031\n",
      "Epoch 12: val_accuracy did not improve from 0.50099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.3750 - loss: 1.8031 - val_accuracy: 0.4750 - val_loss: 1.3944\n",
      "Epoch 13/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.4464 - loss: 1.4368\n",
      "Epoch 13: val_accuracy improved from 0.50099 to 0.51832, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 182ms/step - accuracy: 0.4464 - loss: 1.4368 - val_accuracy: 0.5183 - val_loss: 1.2731\n",
      "Epoch 14/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:01\u001b[0m 167ms/step - accuracy: 0.2500 - loss: 1.9743\n",
      "Epoch 14: val_accuracy improved from 0.51832 to 0.52003, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.2500 - loss: 1.9743 - val_accuracy: 0.5200 - val_loss: 1.2681\n",
      "Epoch 15/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.4670 - loss: 1.3843\n",
      "Epoch 15: val_accuracy did not improve from 0.52003\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 183ms/step - accuracy: 0.4670 - loss: 1.3843 - val_accuracy: 0.4366 - val_loss: 1.5430\n",
      "Epoch 16/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:12\u001b[0m 173ms/step - accuracy: 0.3750 - loss: 1.5816\n",
      "Epoch 16: val_accuracy did not improve from 0.52003\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.3750 - loss: 1.5816 - val_accuracy: 0.4249 - val_loss: 1.5761\n",
      "Epoch 17/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.4856 - loss: 1.3477\n",
      "Epoch 17: val_accuracy improved from 0.52003 to 0.55511, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 183ms/step - accuracy: 0.4856 - loss: 1.3477 - val_accuracy: 0.5551 - val_loss: 1.1664\n",
      "Epoch 18/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:07\u001b[0m 171ms/step - accuracy: 0.6250 - loss: 0.9419\n",
      "Epoch 18: val_accuracy improved from 0.55511 to 0.55653, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.9419 - val_accuracy: 0.5565 - val_loss: 1.1652\n",
      "Epoch 19/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.4921 - loss: 1.3280\n",
      "Epoch 19: val_accuracy improved from 0.55653 to 0.56094, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 183ms/step - accuracy: 0.4921 - loss: 1.3280 - val_accuracy: 0.5609 - val_loss: 1.1507\n",
      "Epoch 20/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:05\u001b[0m 170ms/step - accuracy: 0.6250 - loss: 1.2233\n",
      "Epoch 20: val_accuracy did not improve from 0.56094\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 1.2233 - val_accuracy: 0.5607 - val_loss: 1.1524\n",
      "Epoch 21/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.5009 - loss: 1.3038\n",
      "Epoch 21: val_accuracy improved from 0.56094 to 0.56420, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 184ms/step - accuracy: 0.5009 - loss: 1.3038 - val_accuracy: 0.5642 - val_loss: 1.1481\n",
      "Epoch 22/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m4:52\u001b[0m 162ms/step - accuracy: 0.3750 - loss: 1.6593\n",
      "Epoch 22: val_accuracy improved from 0.56420 to 0.56435, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.3750 - loss: 1.6593 - val_accuracy: 0.5643 - val_loss: 1.1499\n",
      "Epoch 23/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.5186 - loss: 1.2740\n",
      "Epoch 23: val_accuracy did not improve from 0.56435\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 184ms/step - accuracy: 0.5186 - loss: 1.2740 - val_accuracy: 0.5580 - val_loss: 1.1624\n",
      "Epoch 24/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:12\u001b[0m 174ms/step - accuracy: 0.3750 - loss: 1.3533\n",
      "Epoch 24: val_accuracy did not improve from 0.56435\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.3750 - loss: 1.3533 - val_accuracy: 0.5616 - val_loss: 1.1543\n",
      "Epoch 25/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.5263 - loss: 1.2499\n",
      "Epoch 25: val_accuracy improved from 0.56435 to 0.58381, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 183ms/step - accuracy: 0.5263 - loss: 1.2499 - val_accuracy: 0.5838 - val_loss: 1.0968\n",
      "Epoch 26/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:05\u001b[0m 170ms/step - accuracy: 0.3750 - loss: 1.5061\n",
      "Epoch 26: val_accuracy did not improve from 0.58381\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.3750 - loss: 1.5061 - val_accuracy: 0.5832 - val_loss: 1.0973\n",
      "Epoch 27/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.5290 - loss: 1.2376\n",
      "Epoch 27: val_accuracy improved from 0.58381 to 0.59375, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 184ms/step - accuracy: 0.5290 - loss: 1.2376 - val_accuracy: 0.5938 - val_loss: 1.0893\n",
      "Epoch 28/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:08\u001b[0m 172ms/step - accuracy: 0.3750 - loss: 1.8939\n",
      "Epoch 28: val_accuracy did not improve from 0.59375\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.3750 - loss: 1.8939 - val_accuracy: 0.5918 - val_loss: 1.0939\n",
      "Epoch 29/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.5414 - loss: 1.2068\n",
      "Epoch 29: val_accuracy did not improve from 0.59375\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 185ms/step - accuracy: 0.5414 - loss: 1.2068 - val_accuracy: 0.5919 - val_loss: 1.0847\n",
      "Epoch 30/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:31\u001b[0m 184ms/step - accuracy: 0.6250 - loss: 1.2915\n",
      "Epoch 30: val_accuracy did not improve from 0.59375\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 1.2915 - val_accuracy: 0.5930 - val_loss: 1.0843\n",
      "Epoch 31/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.5427 - loss: 1.2046\n",
      "Epoch 31: val_accuracy did not improve from 0.59375\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 185ms/step - accuracy: 0.5427 - loss: 1.2046 - val_accuracy: 0.5879 - val_loss: 1.0817\n",
      "Epoch 32/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:27\u001b[0m 182ms/step - accuracy: 0.3125 - loss: 1.5359\n",
      "Epoch 32: val_accuracy did not improve from 0.59375\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.3125 - loss: 1.5359 - val_accuracy: 0.5915 - val_loss: 1.0766\n",
      "Epoch 33/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.5447 - loss: 1.2006\n",
      "Epoch 33: val_accuracy did not improve from 0.59375\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 184ms/step - accuracy: 0.5447 - loss: 1.2006 - val_accuracy: 0.5930 - val_loss: 1.0829\n",
      "Epoch 34/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:23\u001b[0m 180ms/step - accuracy: 0.4375 - loss: 1.1741\n",
      "Epoch 34: val_accuracy improved from 0.59375 to 0.59503, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.4375 - loss: 1.1741 - val_accuracy: 0.5950 - val_loss: 1.0807\n",
      "Epoch 35/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.5583 - loss: 1.1802\n",
      "Epoch 35: val_accuracy did not improve from 0.59503\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 184ms/step - accuracy: 0.5583 - loss: 1.1802 - val_accuracy: 0.5439 - val_loss: 1.1913\n",
      "Epoch 36/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:13\u001b[0m 174ms/step - accuracy: 0.3750 - loss: 1.2296\n",
      "Epoch 36: val_accuracy did not improve from 0.59503\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.3750 - loss: 1.2296 - val_accuracy: 0.5524 - val_loss: 1.1671\n",
      "Epoch 37/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.5555 - loss: 1.1800\n",
      "Epoch 37: val_accuracy improved from 0.59503 to 0.59574, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 185ms/step - accuracy: 0.5555 - loss: 1.1800 - val_accuracy: 0.5957 - val_loss: 1.0754\n",
      "Epoch 38/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:10\u001b[0m 173ms/step - accuracy: 0.6250 - loss: 1.2105\n",
      "Epoch 38: val_accuracy did not improve from 0.59574\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 1.2105 - val_accuracy: 0.5942 - val_loss: 1.0747\n",
      "Epoch 39/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.5675 - loss: 1.1553\n",
      "Epoch 39: val_accuracy improved from 0.59574 to 0.60810, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 186ms/step - accuracy: 0.5675 - loss: 1.1553 - val_accuracy: 0.6081 - val_loss: 1.0426\n",
      "Epoch 40/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:08\u001b[0m 171ms/step - accuracy: 0.5625 - loss: 1.1665\n",
      "Epoch 40: val_accuracy improved from 0.60810 to 0.60966, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 1.1665 - val_accuracy: 0.6097 - val_loss: 1.0416\n",
      "Epoch 41/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.5499 - loss: 1.1747\n",
      "Epoch 41: val_accuracy did not improve from 0.60966\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 185ms/step - accuracy: 0.5499 - loss: 1.1747 - val_accuracy: 0.5913 - val_loss: 1.0980\n",
      "Epoch 42/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:27\u001b[0m 182ms/step - accuracy: 0.8750 - loss: 0.9076\n",
      "Epoch 42: val_accuracy did not improve from 0.60966\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8750 - loss: 0.9076 - val_accuracy: 0.5952 - val_loss: 1.0863\n",
      "Epoch 43/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.5666 - loss: 1.1438\n",
      "Epoch 43: val_accuracy improved from 0.60966 to 0.61548, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 186ms/step - accuracy: 0.5666 - loss: 1.1438 - val_accuracy: 0.6155 - val_loss: 1.0207\n",
      "Epoch 44/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:03\u001b[0m 169ms/step - accuracy: 0.5000 - loss: 1.2312\n",
      "Epoch 44: val_accuracy improved from 0.61548 to 0.61747, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.5000 - loss: 1.2312 - val_accuracy: 0.6175 - val_loss: 1.0191\n",
      "Epoch 45/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.5645 - loss: 1.1487\n",
      "Epoch 45: val_accuracy did not improve from 0.61747\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 186ms/step - accuracy: 0.5645 - loss: 1.1487 - val_accuracy: 0.6162 - val_loss: 1.0241\n",
      "Epoch 46/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:29\u001b[0m 183ms/step - accuracy: 0.6250 - loss: 1.0582\n",
      "Epoch 46: val_accuracy did not improve from 0.61747\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 1.0582 - val_accuracy: 0.6158 - val_loss: 1.0236\n",
      "Epoch 47/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.5653 - loss: 1.1313\n",
      "Epoch 47: val_accuracy improved from 0.61747 to 0.62116, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 186ms/step - accuracy: 0.5653 - loss: 1.1313 - val_accuracy: 0.6212 - val_loss: 1.0137\n",
      "Epoch 48/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:03\u001b[0m 169ms/step - accuracy: 0.8125 - loss: 0.9363\n",
      "Epoch 48: val_accuracy did not improve from 0.62116\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.9363 - val_accuracy: 0.6193 - val_loss: 1.0162\n",
      "Epoch 49/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.5680 - loss: 1.1359\n",
      "Epoch 49: val_accuracy did not improve from 0.62116\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 186ms/step - accuracy: 0.5680 - loss: 1.1359 - val_accuracy: 0.6170 - val_loss: 1.0217\n",
      "Epoch 50/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:15\u001b[0m 175ms/step - accuracy: 0.8125 - loss: 0.8817\n",
      "Epoch 50: val_accuracy did not improve from 0.62116\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.8817 - val_accuracy: 0.6172 - val_loss: 1.0212\n",
      "Epoch 51/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.5827 - loss: 1.1022\n",
      "Epoch 51: val_accuracy did not improve from 0.62116\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 208ms/step - accuracy: 0.5827 - loss: 1.1022 - val_accuracy: 0.6091 - val_loss: 1.0325\n",
      "Epoch 52/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:24\u001b[0m 180ms/step - accuracy: 0.5625 - loss: 1.2159\n",
      "Epoch 52: val_accuracy did not improve from 0.62116\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 1.2159 - val_accuracy: 0.6091 - val_loss: 1.0311\n",
      "Epoch 53/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.5775 - loss: 1.1152\n",
      "Epoch 53: val_accuracy did not improve from 0.62116\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 228ms/step - accuracy: 0.5775 - loss: 1.1152 - val_accuracy: 0.6146 - val_loss: 1.0320\n",
      "Epoch 54/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:15\u001b[0m 175ms/step - accuracy: 0.7500 - loss: 0.8101\n",
      "Epoch 54: val_accuracy did not improve from 0.62116\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.8101 - val_accuracy: 0.6153 - val_loss: 1.0312\n",
      "Epoch 55/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.5802 - loss: 1.1014\n",
      "Epoch 55: val_accuracy did not improve from 0.62116\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 186ms/step - accuracy: 0.5802 - loss: 1.1014 - val_accuracy: 0.5716 - val_loss: 1.1498\n",
      "Epoch 56/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:21\u001b[0m 178ms/step - accuracy: 0.3750 - loss: 1.3115\n",
      "Epoch 56: val_accuracy did not improve from 0.62116\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.3750 - loss: 1.3115 - val_accuracy: 0.5730 - val_loss: 1.1441\n",
      "Epoch 57/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.5882 - loss: 1.0950\n",
      "Epoch 57: val_accuracy did not improve from 0.62116\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 186ms/step - accuracy: 0.5882 - loss: 1.0950 - val_accuracy: 0.5920 - val_loss: 1.0758\n",
      "Epoch 58/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:06\u001b[0m 171ms/step - accuracy: 0.4375 - loss: 1.6594\n",
      "Epoch 58: val_accuracy did not improve from 0.62116\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.4375 - loss: 1.6594 - val_accuracy: 0.5898 - val_loss: 1.0778\n",
      "Epoch 59/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.5880 - loss: 1.0888\n",
      "Epoch 59: val_accuracy did not improve from 0.62116\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 187ms/step - accuracy: 0.5880 - loss: 1.0888 - val_accuracy: 0.6207 - val_loss: 1.0131\n",
      "Epoch 60/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:29\u001b[0m 183ms/step - accuracy: 0.5625 - loss: 0.9083\n",
      "Epoch 60: val_accuracy did not improve from 0.62116\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 0.9083 - val_accuracy: 0.6210 - val_loss: 1.0140\n",
      "Epoch 61/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.5893 - loss: 1.0839\n",
      "Epoch 61: val_accuracy did not improve from 0.62116\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 186ms/step - accuracy: 0.5893 - loss: 1.0839 - val_accuracy: 0.5837 - val_loss: 1.1087\n",
      "Epoch 62/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:15\u001b[0m 175ms/step - accuracy: 0.5000 - loss: 1.3561\n",
      "Epoch 62: val_accuracy did not improve from 0.62116\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 1.3561 - val_accuracy: 0.5821 - val_loss: 1.1117\n",
      "Epoch 63/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.5936 - loss: 1.0772\n",
      "Epoch 63: val_accuracy improved from 0.62116 to 0.63310, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 186ms/step - accuracy: 0.5936 - loss: 1.0772 - val_accuracy: 0.6331 - val_loss: 0.9828\n",
      "Epoch 64/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:15\u001b[0m 175ms/step - accuracy: 0.6250 - loss: 1.0211\n",
      "Epoch 64: val_accuracy improved from 0.63310 to 0.63381, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 1.0211 - val_accuracy: 0.6338 - val_loss: 0.9808\n",
      "Epoch 65/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.5980 - loss: 1.0713\n",
      "Epoch 65: val_accuracy did not improve from 0.63381\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 186ms/step - accuracy: 0.5980 - loss: 1.0713 - val_accuracy: 0.5764 - val_loss: 1.1259\n",
      "Epoch 66/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:16\u001b[0m 176ms/step - accuracy: 0.5625 - loss: 1.4048\n",
      "Epoch 66: val_accuracy did not improve from 0.63381\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 1.4048 - val_accuracy: 0.5749 - val_loss: 1.1328\n",
      "Epoch 67/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.5966 - loss: 1.0681\n",
      "Epoch 67: val_accuracy did not improve from 0.63381\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 186ms/step - accuracy: 0.5965 - loss: 1.0681 - val_accuracy: 0.6233 - val_loss: 1.0035\n",
      "Epoch 68/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:25\u001b[0m 181ms/step - accuracy: 0.5000 - loss: 1.3350\n",
      "Epoch 68: val_accuracy did not improve from 0.63381\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 1.3350 - val_accuracy: 0.6203 - val_loss: 1.0067\n",
      "Epoch 69/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.6001 - loss: 1.0674\n",
      "Epoch 69: val_accuracy improved from 0.63381 to 0.64233, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 187ms/step - accuracy: 0.6001 - loss: 1.0674 - val_accuracy: 0.6423 - val_loss: 0.9767\n",
      "Epoch 70/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:06\u001b[0m 170ms/step - accuracy: 0.6875 - loss: 1.1082\n",
      "Epoch 70: val_accuracy improved from 0.64233 to 0.64318, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 1.1082 - val_accuracy: 0.6432 - val_loss: 0.9784\n",
      "Epoch 71/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6007 - loss: 1.0618\n",
      "Epoch 71: val_accuracy did not improve from 0.64318\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 188ms/step - accuracy: 0.6007 - loss: 1.0618 - val_accuracy: 0.6192 - val_loss: 1.0238\n",
      "Epoch 72/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:16\u001b[0m 209ms/step - accuracy: 0.4375 - loss: 1.0460\n",
      "Epoch 72: val_accuracy did not improve from 0.64318\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.4375 - loss: 1.0460 - val_accuracy: 0.6197 - val_loss: 1.0218\n",
      "Epoch 73/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6015 - loss: 1.0545\n",
      "Epoch 73: val_accuracy did not improve from 0.64318\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 188ms/step - accuracy: 0.6015 - loss: 1.0545 - val_accuracy: 0.6396 - val_loss: 0.9698\n",
      "Epoch 74/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:41\u001b[0m 189ms/step - accuracy: 0.5000 - loss: 1.4021\n",
      "Epoch 74: val_accuracy did not improve from 0.64318\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 1.4021 - val_accuracy: 0.6402 - val_loss: 0.9682\n",
      "Epoch 75/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.6055 - loss: 1.0408\n",
      "Epoch 75: val_accuracy did not improve from 0.64318\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 189ms/step - accuracy: 0.6055 - loss: 1.0408 - val_accuracy: 0.6278 - val_loss: 0.9995\n",
      "Epoch 76/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:23\u001b[0m 180ms/step - accuracy: 0.6250 - loss: 1.2392\n",
      "Epoch 76: val_accuracy did not improve from 0.64318\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.6250 - loss: 1.2392 - val_accuracy: 0.6276 - val_loss: 1.0005\n",
      "Epoch 77/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.6066 - loss: 1.0506\n",
      "Epoch 77: val_accuracy did not improve from 0.64318\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 189ms/step - accuracy: 0.6066 - loss: 1.0506 - val_accuracy: 0.6351 - val_loss: 0.9843\n",
      "Epoch 78/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:33\u001b[0m 185ms/step - accuracy: 0.3750 - loss: 1.4041\n",
      "Epoch 78: val_accuracy did not improve from 0.64318\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.3750 - loss: 1.4041 - val_accuracy: 0.6349 - val_loss: 0.9828\n",
      "Epoch 79/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.6142 - loss: 1.0281\n",
      "Epoch 79: val_accuracy did not improve from 0.64318\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 189ms/step - accuracy: 0.6142 - loss: 1.0281 - val_accuracy: 0.6406 - val_loss: 0.9625\n",
      "Epoch 80/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:20\u001b[0m 178ms/step - accuracy: 0.6250 - loss: 0.8170\n",
      "Epoch 80: val_accuracy improved from 0.64318 to 0.64375, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.8170 - val_accuracy: 0.6438 - val_loss: 0.9608\n",
      "Epoch 81/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.6043 - loss: 1.0417\n",
      "Epoch 81: val_accuracy did not improve from 0.64375\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 189ms/step - accuracy: 0.6043 - loss: 1.0417 - val_accuracy: 0.6423 - val_loss: 0.9697\n",
      "Epoch 82/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:29\u001b[0m 183ms/step - accuracy: 0.5625 - loss: 0.8392\n",
      "Epoch 82: val_accuracy did not improve from 0.64375\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 0.8392 - val_accuracy: 0.6430 - val_loss: 0.9691\n",
      "Epoch 83/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.6124 - loss: 1.0289\n",
      "Epoch 83: val_accuracy did not improve from 0.64375\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 189ms/step - accuracy: 0.6124 - loss: 1.0289 - val_accuracy: 0.6409 - val_loss: 0.9567\n",
      "Epoch 84/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:37\u001b[0m 187ms/step - accuracy: 0.7500 - loss: 0.8043\n",
      "Epoch 84: val_accuracy did not improve from 0.64375\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.8043 - val_accuracy: 0.6419 - val_loss: 0.9560\n",
      "Epoch 85/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.6151 - loss: 1.0248\n",
      "Epoch 85: val_accuracy did not improve from 0.64375\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 189ms/step - accuracy: 0.6151 - loss: 1.0248 - val_accuracy: 0.6030 - val_loss: 1.0468\n",
      "Epoch 86/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:28\u001b[0m 183ms/step - accuracy: 0.5625 - loss: 1.1200\n",
      "Epoch 86: val_accuracy did not improve from 0.64375\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 1.1200 - val_accuracy: 0.5999 - val_loss: 1.0525\n",
      "Epoch 87/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.6158 - loss: 1.0251\n",
      "Epoch 87: val_accuracy did not improve from 0.64375\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 190ms/step - accuracy: 0.6158 - loss: 1.0251 - val_accuracy: 0.6134 - val_loss: 1.0332\n",
      "Epoch 88/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:20\u001b[0m 178ms/step - accuracy: 0.5625 - loss: 1.0674\n",
      "Epoch 88: val_accuracy did not improve from 0.64375\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 1.0674 - val_accuracy: 0.6141 - val_loss: 1.0285\n",
      "Epoch 89/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.6177 - loss: 1.0141\n",
      "Epoch 89: val_accuracy improved from 0.64375 to 0.64801, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 191ms/step - accuracy: 0.6177 - loss: 1.0141 - val_accuracy: 0.6480 - val_loss: 0.9694\n",
      "Epoch 90/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:15\u001b[0m 175ms/step - accuracy: 0.6875 - loss: 0.8447\n",
      "Epoch 90: val_accuracy improved from 0.64801 to 0.64943, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.8447 - val_accuracy: 0.6494 - val_loss: 0.9693\n",
      "Epoch 91/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.6188 - loss: 1.0198\n",
      "Epoch 91: val_accuracy did not improve from 0.64943\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 189ms/step - accuracy: 0.6188 - loss: 1.0198 - val_accuracy: 0.6324 - val_loss: 0.9965\n",
      "Epoch 92/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:25\u001b[0m 181ms/step - accuracy: 0.5625 - loss: 1.0272\n",
      "Epoch 92: val_accuracy did not improve from 0.64943\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 1.0272 - val_accuracy: 0.6328 - val_loss: 0.9942\n",
      "Epoch 93/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.6216 - loss: 1.0073\n",
      "Epoch 93: val_accuracy did not improve from 0.64943\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 190ms/step - accuracy: 0.6216 - loss: 1.0073 - val_accuracy: 0.6311 - val_loss: 0.9941\n",
      "Epoch 94/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:34\u001b[0m 186ms/step - accuracy: 0.4375 - loss: 1.0161\n",
      "Epoch 94: val_accuracy did not improve from 0.64943\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.4375 - loss: 1.0161 - val_accuracy: 0.6317 - val_loss: 0.9949\n",
      "Epoch 95/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.6209 - loss: 1.0138\n",
      "Epoch 95: val_accuracy did not improve from 0.64943\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 193ms/step - accuracy: 0.6209 - loss: 1.0138 - val_accuracy: 0.6247 - val_loss: 0.9986\n",
      "Epoch 96/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:19\u001b[0m 177ms/step - accuracy: 0.6875 - loss: 0.9433\n",
      "Epoch 96: val_accuracy did not improve from 0.64943\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.9433 - val_accuracy: 0.6260 - val_loss: 0.9961\n",
      "Epoch 97/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.6244 - loss: 0.9972\n",
      "Epoch 97: val_accuracy did not improve from 0.64943\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 196ms/step - accuracy: 0.6244 - loss: 0.9972 - val_accuracy: 0.6487 - val_loss: 0.9494\n",
      "Epoch 98/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:18\u001b[0m 177ms/step - accuracy: 0.6875 - loss: 0.8147\n",
      "Epoch 98: val_accuracy did not improve from 0.64943\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.8147 - val_accuracy: 0.6487 - val_loss: 0.9499\n",
      "Epoch 99/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.6287 - loss: 0.9947\n",
      "Epoch 99: val_accuracy did not improve from 0.64943\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 192ms/step - accuracy: 0.6287 - loss: 0.9947 - val_accuracy: 0.6213 - val_loss: 1.0083\n",
      "Epoch 100/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:14\u001b[0m 175ms/step - accuracy: 0.6875 - loss: 0.9510\n",
      "Epoch 100: val_accuracy did not improve from 0.64943\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.9510 - val_accuracy: 0.6173 - val_loss: 1.0189\n",
      "Epoch 101/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.6290 - loss: 0.9825\n",
      "Epoch 101: val_accuracy improved from 0.64943 to 0.66207, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 191ms/step - accuracy: 0.6290 - loss: 0.9825 - val_accuracy: 0.6621 - val_loss: 0.9251\n",
      "Epoch 102/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:08\u001b[0m 171ms/step - accuracy: 0.5625 - loss: 1.0240\n",
      "Epoch 102: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 1.0240 - val_accuracy: 0.6619 - val_loss: 0.9261\n",
      "Epoch 103/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.6304 - loss: 0.9841\n",
      "Epoch 103: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 190ms/step - accuracy: 0.6303 - loss: 0.9841 - val_accuracy: 0.6537 - val_loss: 0.9391\n",
      "Epoch 104/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:19\u001b[0m 178ms/step - accuracy: 0.6875 - loss: 1.0945\n",
      "Epoch 104: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 1.0945 - val_accuracy: 0.6537 - val_loss: 0.9395\n",
      "Epoch 105/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.6278 - loss: 0.9915\n",
      "Epoch 105: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 188ms/step - accuracy: 0.6278 - loss: 0.9914 - val_accuracy: 0.6357 - val_loss: 0.9907\n",
      "Epoch 106/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:22\u001b[0m 179ms/step - accuracy: 0.7500 - loss: 0.7620\n",
      "Epoch 106: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.7620 - val_accuracy: 0.6352 - val_loss: 0.9926\n",
      "Epoch 107/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6291 - loss: 0.9831\n",
      "Epoch 107: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 187ms/step - accuracy: 0.6291 - loss: 0.9831 - val_accuracy: 0.6436 - val_loss: 0.9748\n",
      "Epoch 108/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:12\u001b[0m 174ms/step - accuracy: 0.4375 - loss: 1.3226\n",
      "Epoch 108: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.4375 - loss: 1.3226 - val_accuracy: 0.6447 - val_loss: 0.9700\n",
      "Epoch 109/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6281 - loss: 0.9879\n",
      "Epoch 109: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 188ms/step - accuracy: 0.6281 - loss: 0.9879 - val_accuracy: 0.6004 - val_loss: 1.0728\n",
      "Epoch 110/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:23\u001b[0m 180ms/step - accuracy: 0.8125 - loss: 0.6367\n",
      "Epoch 110: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.6367 - val_accuracy: 0.6010 - val_loss: 1.0710\n",
      "Epoch 111/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.6295 - loss: 0.9722\n",
      "Epoch 111: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 188ms/step - accuracy: 0.6295 - loss: 0.9722 - val_accuracy: 0.6561 - val_loss: 0.9429\n",
      "Epoch 112/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:45\u001b[0m 192ms/step - accuracy: 0.7500 - loss: 0.6997\n",
      "Epoch 112: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.6997 - val_accuracy: 0.6547 - val_loss: 0.9406\n",
      "Epoch 113/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.6369 - loss: 0.9772\n",
      "Epoch 113: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 190ms/step - accuracy: 0.6369 - loss: 0.9772 - val_accuracy: 0.6484 - val_loss: 0.9672\n",
      "Epoch 114/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:30\u001b[0m 184ms/step - accuracy: 0.6875 - loss: 0.8973\n",
      "Epoch 114: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.8973 - val_accuracy: 0.6497 - val_loss: 0.9656\n",
      "Epoch 115/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.6389 - loss: 0.9603\n",
      "Epoch 115: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 191ms/step - accuracy: 0.6389 - loss: 0.9603 - val_accuracy: 0.6568 - val_loss: 0.9369\n",
      "Epoch 116/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:25\u001b[0m 181ms/step - accuracy: 0.6875 - loss: 0.7778\n",
      "Epoch 116: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.7778 - val_accuracy: 0.6557 - val_loss: 0.9381\n",
      "Epoch 117/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.6363 - loss: 0.9675\n",
      "Epoch 117: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 191ms/step - accuracy: 0.6363 - loss: 0.9675 - val_accuracy: 0.6592 - val_loss: 0.9368\n",
      "Epoch 118/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:29\u001b[0m 183ms/step - accuracy: 0.6250 - loss: 1.0921\n",
      "Epoch 118: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 1.0921 - val_accuracy: 0.6580 - val_loss: 0.9394\n",
      "Epoch 119/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.6338 - loss: 0.9684\n",
      "Epoch 119: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 191ms/step - accuracy: 0.6338 - loss: 0.9684 - val_accuracy: 0.6295 - val_loss: 1.0057\n",
      "Epoch 120/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:22\u001b[0m 179ms/step - accuracy: 0.8125 - loss: 0.5945\n",
      "Epoch 120: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.5945 - val_accuracy: 0.6287 - val_loss: 1.0072\n",
      "Epoch 121/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.6434 - loss: 0.9520\n",
      "Epoch 121: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 192ms/step - accuracy: 0.6434 - loss: 0.9520 - val_accuracy: 0.6445 - val_loss: 0.9694\n",
      "Epoch 122/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:12\u001b[0m 173ms/step - accuracy: 0.5000 - loss: 1.2824\n",
      "Epoch 122: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 1.2824 - val_accuracy: 0.6483 - val_loss: 0.9655\n",
      "Epoch 123/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.6433 - loss: 0.9520\n",
      "Epoch 123: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 191ms/step - accuracy: 0.6433 - loss: 0.9520 - val_accuracy: 0.6339 - val_loss: 0.9962\n",
      "Epoch 124/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:29\u001b[0m 183ms/step - accuracy: 0.8125 - loss: 0.6476\n",
      "Epoch 124: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.6476 - val_accuracy: 0.6338 - val_loss: 0.9960\n",
      "Epoch 125/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.6444 - loss: 0.9442\n",
      "Epoch 125: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 195ms/step - accuracy: 0.6444 - loss: 0.9442 - val_accuracy: 0.6536 - val_loss: 0.9580\n",
      "Epoch 126/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:33\u001b[0m 185ms/step - accuracy: 0.6250 - loss: 0.6903\n",
      "Epoch 126: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6250 - loss: 0.6903 - val_accuracy: 0.6530 - val_loss: 0.9624\n",
      "Epoch 127/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.6424 - loss: 0.9508\n",
      "Epoch 127: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 197ms/step - accuracy: 0.6424 - loss: 0.9508 - val_accuracy: 0.6452 - val_loss: 0.9671\n",
      "Epoch 128/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:45\u001b[0m 192ms/step - accuracy: 0.5625 - loss: 0.8752\n",
      "Epoch 128: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 0.8752 - val_accuracy: 0.6438 - val_loss: 0.9675\n",
      "Epoch 129/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.6514 - loss: 0.9327\n",
      "Epoch 129: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 195ms/step - accuracy: 0.6514 - loss: 0.9327 - val_accuracy: 0.6266 - val_loss: 1.0159\n",
      "Epoch 130/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:26\u001b[0m 181ms/step - accuracy: 0.6875 - loss: 0.7713\n",
      "Epoch 130: val_accuracy did not improve from 0.66207\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.7713 - val_accuracy: 0.6251 - val_loss: 1.0188\n",
      "Epoch 131/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.6459 - loss: 0.9497\n",
      "Epoch 131: val_accuracy improved from 0.66207 to 0.66605, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 194ms/step - accuracy: 0.6459 - loss: 0.9497 - val_accuracy: 0.6661 - val_loss: 0.9176\n",
      "Epoch 132/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:42\u001b[0m 190ms/step - accuracy: 0.8125 - loss: 0.6127\n",
      "Epoch 132: val_accuracy did not improve from 0.66605\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.6127 - val_accuracy: 0.6658 - val_loss: 0.9174\n",
      "Epoch 133/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.6469 - loss: 0.9392\n",
      "Epoch 133: val_accuracy improved from 0.66605 to 0.66648, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 193ms/step - accuracy: 0.6469 - loss: 0.9392 - val_accuracy: 0.6665 - val_loss: 0.9206\n",
      "Epoch 134/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:27\u001b[0m 182ms/step - accuracy: 0.6250 - loss: 1.0227\n",
      "Epoch 134: val_accuracy improved from 0.66648 to 0.66662, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 1.0227 - val_accuracy: 0.6666 - val_loss: 0.9209\n",
      "Epoch 135/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.6548 - loss: 0.9312\n",
      "Epoch 135: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 193ms/step - accuracy: 0.6548 - loss: 0.9312 - val_accuracy: 0.6629 - val_loss: 0.9211\n",
      "Epoch 136/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:31\u001b[0m 184ms/step - accuracy: 0.5625 - loss: 1.2506\n",
      "Epoch 136: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 1.2506 - val_accuracy: 0.6635 - val_loss: 0.9193\n",
      "Epoch 137/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.6490 - loss: 0.9325\n",
      "Epoch 137: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 193ms/step - accuracy: 0.6490 - loss: 0.9325 - val_accuracy: 0.6385 - val_loss: 0.9767\n",
      "Epoch 138/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:26\u001b[0m 182ms/step - accuracy: 0.6250 - loss: 0.6769\n",
      "Epoch 138: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.6769 - val_accuracy: 0.6419 - val_loss: 0.9699\n",
      "Epoch 139/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.6525 - loss: 0.9252\n",
      "Epoch 139: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 193ms/step - accuracy: 0.6525 - loss: 0.9252 - val_accuracy: 0.6487 - val_loss: 0.9640\n",
      "Epoch 140/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:23\u001b[0m 180ms/step - accuracy: 0.6250 - loss: 0.9767\n",
      "Epoch 140: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.9767 - val_accuracy: 0.6483 - val_loss: 0.9652\n",
      "Epoch 141/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.6551 - loss: 0.9257\n",
      "Epoch 141: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 194ms/step - accuracy: 0.6551 - loss: 0.9257 - val_accuracy: 0.6497 - val_loss: 0.9677\n",
      "Epoch 142/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:14\u001b[0m 175ms/step - accuracy: 0.7500 - loss: 0.8974\n",
      "Epoch 142: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.8974 - val_accuracy: 0.6504 - val_loss: 0.9640\n",
      "Epoch 143/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.6490 - loss: 0.9341\n",
      "Epoch 143: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 194ms/step - accuracy: 0.6490 - loss: 0.9341 - val_accuracy: 0.6638 - val_loss: 0.9346\n",
      "Epoch 144/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:29\u001b[0m 183ms/step - accuracy: 0.6250 - loss: 0.8008\n",
      "Epoch 144: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.8008 - val_accuracy: 0.6626 - val_loss: 0.9341\n",
      "Epoch 145/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.6653 - loss: 0.9003\n",
      "Epoch 145: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 194ms/step - accuracy: 0.6653 - loss: 0.9003 - val_accuracy: 0.6651 - val_loss: 0.9243\n",
      "Epoch 146/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:23\u001b[0m 180ms/step - accuracy: 0.6875 - loss: 0.7893\n",
      "Epoch 146: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.7893 - val_accuracy: 0.6632 - val_loss: 0.9273\n",
      "Epoch 147/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.6528 - loss: 0.9207\n",
      "Epoch 147: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 194ms/step - accuracy: 0.6528 - loss: 0.9207 - val_accuracy: 0.6643 - val_loss: 0.9115\n",
      "Epoch 148/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:36\u001b[0m 187ms/step - accuracy: 0.6250 - loss: 1.4867\n",
      "Epoch 148: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 1.4867 - val_accuracy: 0.6651 - val_loss: 0.9109\n",
      "Epoch 149/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.6556 - loss: 0.9129\n",
      "Epoch 149: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 195ms/step - accuracy: 0.6556 - loss: 0.9129 - val_accuracy: 0.6594 - val_loss: 0.9443\n",
      "Epoch 150/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:35\u001b[0m 186ms/step - accuracy: 0.6250 - loss: 1.0428\n",
      "Epoch 150: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 1.0428 - val_accuracy: 0.6601 - val_loss: 0.9443\n",
      "Epoch 151/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.6625 - loss: 0.9149\n",
      "Epoch 151: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 195ms/step - accuracy: 0.6625 - loss: 0.9149 - val_accuracy: 0.6570 - val_loss: 0.9318\n",
      "Epoch 152/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:40\u001b[0m 189ms/step - accuracy: 0.7500 - loss: 0.5229\n",
      "Epoch 152: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.5229 - val_accuracy: 0.6582 - val_loss: 0.9307\n",
      "Epoch 153/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.6627 - loss: 0.9028\n",
      "Epoch 153: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 194ms/step - accuracy: 0.6627 - loss: 0.9028 - val_accuracy: 0.6648 - val_loss: 0.9189\n",
      "Epoch 154/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:31\u001b[0m 184ms/step - accuracy: 0.5625 - loss: 1.4999\n",
      "Epoch 154: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 1.4999 - val_accuracy: 0.6659 - val_loss: 0.9179\n",
      "Epoch 155/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.6631 - loss: 0.8967\n",
      "Epoch 155: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 195ms/step - accuracy: 0.6631 - loss: 0.8967 - val_accuracy: 0.6536 - val_loss: 0.9339\n",
      "Epoch 156/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:46\u001b[0m 192ms/step - accuracy: 0.5000 - loss: 1.0908\n",
      "Epoch 156: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 1.0908 - val_accuracy: 0.6524 - val_loss: 0.9371\n",
      "Epoch 157/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.6640 - loss: 0.9070\n",
      "Epoch 157: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 195ms/step - accuracy: 0.6640 - loss: 0.9070 - val_accuracy: 0.6466 - val_loss: 0.9895\n",
      "Epoch 158/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:38\u001b[0m 188ms/step - accuracy: 0.6875 - loss: 0.9687\n",
      "Epoch 158: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.9687 - val_accuracy: 0.6479 - val_loss: 0.9893\n",
      "Epoch 159/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.6662 - loss: 0.9017\n",
      "Epoch 159: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 196ms/step - accuracy: 0.6662 - loss: 0.9017 - val_accuracy: 0.6060 - val_loss: 1.0808\n",
      "Epoch 160/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:41\u001b[0m 223ms/step - accuracy: 0.6250 - loss: 1.0490\n",
      "Epoch 160: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 1.0490 - val_accuracy: 0.6040 - val_loss: 1.0853\n",
      "Epoch 161/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.6626 - loss: 0.8976\n",
      "Epoch 161: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 196ms/step - accuracy: 0.6626 - loss: 0.8976 - val_accuracy: 0.6656 - val_loss: 0.9256\n",
      "Epoch 162/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:34\u001b[0m 186ms/step - accuracy: 0.6875 - loss: 0.8347\n",
      "Epoch 162: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.8347 - val_accuracy: 0.6665 - val_loss: 0.9232\n",
      "Epoch 163/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.6628 - loss: 0.8897\n",
      "Epoch 163: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 196ms/step - accuracy: 0.6628 - loss: 0.8897 - val_accuracy: 0.6527 - val_loss: 0.9711\n",
      "Epoch 164/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:30\u001b[0m 183ms/step - accuracy: 0.6250 - loss: 1.0766\n",
      "Epoch 164: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 1.0766 - val_accuracy: 0.6520 - val_loss: 0.9748\n",
      "Epoch 165/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.6681 - loss: 0.8910\n",
      "Epoch 165: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 197ms/step - accuracy: 0.6681 - loss: 0.8910 - val_accuracy: 0.6241 - val_loss: 1.0246\n",
      "Epoch 166/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:54\u001b[0m 197ms/step - accuracy: 0.3750 - loss: 1.3738\n",
      "Epoch 166: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.3750 - loss: 1.3738 - val_accuracy: 0.6240 - val_loss: 1.0259\n",
      "Epoch 167/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.6651 - loss: 0.8843\n",
      "Epoch 167: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 197ms/step - accuracy: 0.6651 - loss: 0.8843 - val_accuracy: 0.6545 - val_loss: 0.9504\n",
      "Epoch 168/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:42\u001b[0m 191ms/step - accuracy: 0.6875 - loss: 0.7620\n",
      "Epoch 168: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.7620 - val_accuracy: 0.6557 - val_loss: 0.9494\n",
      "Epoch 169/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.6662 - loss: 0.8883\n",
      "Epoch 169: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 197ms/step - accuracy: 0.6662 - loss: 0.8883 - val_accuracy: 0.6636 - val_loss: 0.9390\n",
      "Epoch 170/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:48\u001b[0m 193ms/step - accuracy: 0.7500 - loss: 0.7111\n",
      "Epoch 170: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.7111 - val_accuracy: 0.6645 - val_loss: 0.9368\n",
      "Epoch 171/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.6684 - loss: 0.8928\n",
      "Epoch 171: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 197ms/step - accuracy: 0.6684 - loss: 0.8928 - val_accuracy: 0.6618 - val_loss: 0.9285\n",
      "Epoch 172/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:34\u001b[0m 186ms/step - accuracy: 0.6875 - loss: 0.8811\n",
      "Epoch 172: val_accuracy did not improve from 0.66662\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.8811 - val_accuracy: 0.6605 - val_loss: 0.9339\n",
      "Epoch 173/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.6692 - loss: 0.8710\n",
      "Epoch 173: val_accuracy improved from 0.66662 to 0.66875, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 199ms/step - accuracy: 0.6692 - loss: 0.8710 - val_accuracy: 0.6687 - val_loss: 0.9386\n",
      "Epoch 174/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:30\u001b[0m 184ms/step - accuracy: 0.5625 - loss: 1.0765\n",
      "Epoch 174: val_accuracy improved from 0.66875 to 0.67003, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 1.0765 - val_accuracy: 0.6700 - val_loss: 0.9364\n",
      "Epoch 175/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.6727 - loss: 0.8762\n",
      "Epoch 175: val_accuracy improved from 0.67003 to 0.68011, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 198ms/step - accuracy: 0.6727 - loss: 0.8763 - val_accuracy: 0.6801 - val_loss: 0.9048\n",
      "Epoch 176/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:19\u001b[0m 177ms/step - accuracy: 0.6250 - loss: 1.1798\n",
      "Epoch 176: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 1.1798 - val_accuracy: 0.6795 - val_loss: 0.9070\n",
      "Epoch 177/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.6731 - loss: 0.8668\n",
      "Epoch 177: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 198ms/step - accuracy: 0.6731 - loss: 0.8668 - val_accuracy: 0.6717 - val_loss: 0.9157\n",
      "Epoch 178/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:33\u001b[0m 185ms/step - accuracy: 0.5625 - loss: 0.9070\n",
      "Epoch 178: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 0.9070 - val_accuracy: 0.6717 - val_loss: 0.9162\n",
      "Epoch 179/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.6732 - loss: 0.8688\n",
      "Epoch 179: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 198ms/step - accuracy: 0.6732 - loss: 0.8688 - val_accuracy: 0.6659 - val_loss: 0.9375\n",
      "Epoch 180/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:39\u001b[0m 188ms/step - accuracy: 0.6250 - loss: 0.6227\n",
      "Epoch 180: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.6227 - val_accuracy: 0.6689 - val_loss: 0.9333\n",
      "Epoch 181/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.6746 - loss: 0.8691\n",
      "Epoch 181: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 200ms/step - accuracy: 0.6746 - loss: 0.8691 - val_accuracy: 0.6722 - val_loss: 0.9279\n",
      "Epoch 182/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:49\u001b[0m 194ms/step - accuracy: 0.6875 - loss: 0.7138\n",
      "Epoch 182: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.7138 - val_accuracy: 0.6695 - val_loss: 0.9311\n",
      "Epoch 183/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.6801 - loss: 0.8581\n",
      "Epoch 183: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 199ms/step - accuracy: 0.6801 - loss: 0.8581 - val_accuracy: 0.6636 - val_loss: 0.9430\n",
      "Epoch 184/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:39\u001b[0m 189ms/step - accuracy: 0.7500 - loss: 0.6277\n",
      "Epoch 184: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.6277 - val_accuracy: 0.6616 - val_loss: 0.9450\n",
      "Epoch 185/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.6745 - loss: 0.8672\n",
      "Epoch 185: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 199ms/step - accuracy: 0.6745 - loss: 0.8672 - val_accuracy: 0.6695 - val_loss: 0.9217\n",
      "Epoch 186/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:44\u001b[0m 191ms/step - accuracy: 0.7500 - loss: 0.7279\n",
      "Epoch 186: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.7279 - val_accuracy: 0.6693 - val_loss: 0.9209\n",
      "Epoch 187/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.6767 - loss: 0.8653\n",
      "Epoch 187: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 199ms/step - accuracy: 0.6767 - loss: 0.8653 - val_accuracy: 0.6457 - val_loss: 0.9842\n",
      "Epoch 188/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:36\u001b[0m 187ms/step - accuracy: 0.6250 - loss: 0.9318\n",
      "Epoch 188: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.9318 - val_accuracy: 0.6499 - val_loss: 0.9770\n",
      "Epoch 189/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.6759 - loss: 0.8610\n",
      "Epoch 189: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 199ms/step - accuracy: 0.6759 - loss: 0.8610 - val_accuracy: 0.6683 - val_loss: 0.9224\n",
      "Epoch 190/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:42\u001b[0m 190ms/step - accuracy: 0.6875 - loss: 0.7833\n",
      "Epoch 190: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.7833 - val_accuracy: 0.6705 - val_loss: 0.9193\n",
      "Epoch 191/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.6833 - loss: 0.8523\n",
      "Epoch 191: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 200ms/step - accuracy: 0.6833 - loss: 0.8523 - val_accuracy: 0.6297 - val_loss: 1.0505\n",
      "Epoch 192/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:44\u001b[0m 191ms/step - accuracy: 0.5625 - loss: 1.1094\n",
      "Epoch 192: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 1.1094 - val_accuracy: 0.6295 - val_loss: 1.0485\n",
      "Epoch 193/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.6838 - loss: 0.8390\n",
      "Epoch 193: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 205ms/step - accuracy: 0.6838 - loss: 0.8390 - val_accuracy: 0.6104 - val_loss: 1.1082\n",
      "Epoch 194/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:01\u001b[0m 201ms/step - accuracy: 0.6250 - loss: 0.8953\n",
      "Epoch 194: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.8953 - val_accuracy: 0.6116 - val_loss: 1.1048\n",
      "Epoch 195/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.6797 - loss: 0.8594\n",
      "Epoch 195: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 202ms/step - accuracy: 0.6797 - loss: 0.8594 - val_accuracy: 0.6726 - val_loss: 0.9230\n",
      "Epoch 196/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:44\u001b[0m 191ms/step - accuracy: 0.6250 - loss: 1.1932\n",
      "Epoch 196: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.6250 - loss: 1.1932 - val_accuracy: 0.6741 - val_loss: 0.9220\n",
      "Epoch 197/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.6843 - loss: 0.8425\n",
      "Epoch 197: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 202ms/step - accuracy: 0.6843 - loss: 0.8425 - val_accuracy: 0.6761 - val_loss: 0.9276\n",
      "Epoch 198/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:54\u001b[0m 197ms/step - accuracy: 0.8750 - loss: 0.4487\n",
      "Epoch 198: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8750 - loss: 0.4487 - val_accuracy: 0.6747 - val_loss: 0.9284\n",
      "Epoch 199/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.6866 - loss: 0.8451\n",
      "Epoch 199: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 202ms/step - accuracy: 0.6866 - loss: 0.8451 - val_accuracy: 0.6695 - val_loss: 0.9194\n",
      "Epoch 200/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:37\u001b[0m 187ms/step - accuracy: 0.6250 - loss: 1.0399\n",
      "Epoch 200: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.6250 - loss: 1.0399 - val_accuracy: 0.6702 - val_loss: 0.9190\n",
      "Epoch 201/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.6846 - loss: 0.8322\n",
      "Epoch 201: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 202ms/step - accuracy: 0.6846 - loss: 0.8322 - val_accuracy: 0.6676 - val_loss: 0.9333\n",
      "Epoch 202/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:51\u001b[0m 195ms/step - accuracy: 0.6250 - loss: 1.0040\n",
      "Epoch 202: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 1.0040 - val_accuracy: 0.6679 - val_loss: 0.9333\n",
      "Epoch 203/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.6919 - loss: 0.8330\n",
      "Epoch 203: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 204ms/step - accuracy: 0.6919 - loss: 0.8330 - val_accuracy: 0.6616 - val_loss: 0.9338\n",
      "Epoch 204/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:49\u001b[0m 194ms/step - accuracy: 0.6250 - loss: 0.8573\n",
      "Epoch 204: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.8573 - val_accuracy: 0.6601 - val_loss: 0.9360\n",
      "Epoch 205/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.6877 - loss: 0.8271\n",
      "Epoch 205: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 202ms/step - accuracy: 0.6877 - loss: 0.8271 - val_accuracy: 0.6489 - val_loss: 0.9775\n",
      "Epoch 206/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:50\u001b[0m 195ms/step - accuracy: 0.7500 - loss: 0.8893\n",
      "Epoch 206: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.8893 - val_accuracy: 0.6472 - val_loss: 0.9830\n",
      "Epoch 207/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.6895 - loss: 0.8347\n",
      "Epoch 207: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 205ms/step - accuracy: 0.6895 - loss: 0.8347 - val_accuracy: 0.6271 - val_loss: 1.0409\n",
      "Epoch 208/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:50\u001b[0m 195ms/step - accuracy: 0.8125 - loss: 0.5554\n",
      "Epoch 208: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.5554 - val_accuracy: 0.6274 - val_loss: 1.0376\n",
      "Epoch 209/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.6943 - loss: 0.8269\n",
      "Epoch 209: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 204ms/step - accuracy: 0.6943 - loss: 0.8269 - val_accuracy: 0.6251 - val_loss: 1.0594\n",
      "Epoch 210/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:44\u001b[0m 191ms/step - accuracy: 0.5625 - loss: 1.1100\n",
      "Epoch 210: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 1.1100 - val_accuracy: 0.6257 - val_loss: 1.0583\n",
      "Epoch 211/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.6860 - loss: 0.8437\n",
      "Epoch 211: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 207ms/step - accuracy: 0.6860 - loss: 0.8437 - val_accuracy: 0.6663 - val_loss: 0.9468\n",
      "Epoch 212/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:49\u001b[0m 194ms/step - accuracy: 0.6250 - loss: 0.7662\n",
      "Epoch 212: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.7662 - val_accuracy: 0.6655 - val_loss: 0.9466\n",
      "Epoch 213/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.6945 - loss: 0.8212\n",
      "Epoch 213: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 201ms/step - accuracy: 0.6945 - loss: 0.8212 - val_accuracy: 0.6585 - val_loss: 0.9808\n",
      "Epoch 214/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:39\u001b[0m 188ms/step - accuracy: 0.8125 - loss: 0.5692\n",
      "Epoch 214: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.5692 - val_accuracy: 0.6599 - val_loss: 0.9789\n",
      "Epoch 215/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.6953 - loss: 0.8274\n",
      "Epoch 215: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 202ms/step - accuracy: 0.6953 - loss: 0.8274 - val_accuracy: 0.6555 - val_loss: 0.9706\n",
      "Epoch 216/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:09\u001b[0m 205ms/step - accuracy: 0.6875 - loss: 0.9538\n",
      "Epoch 216: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.9538 - val_accuracy: 0.6550 - val_loss: 0.9749\n",
      "Epoch 217/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.6912 - loss: 0.8317\n",
      "Epoch 217: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 204ms/step - accuracy: 0.6912 - loss: 0.8317 - val_accuracy: 0.6520 - val_loss: 0.9857\n",
      "Epoch 218/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:45\u001b[0m 192ms/step - accuracy: 0.7500 - loss: 0.7032\n",
      "Epoch 218: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.7032 - val_accuracy: 0.6540 - val_loss: 0.9819\n",
      "Epoch 219/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.6946 - loss: 0.8170\n",
      "Epoch 219: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 204ms/step - accuracy: 0.6946 - loss: 0.8170 - val_accuracy: 0.6615 - val_loss: 0.9713\n",
      "Epoch 220/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:42\u001b[0m 190ms/step - accuracy: 0.8750 - loss: 0.5662\n",
      "Epoch 220: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8750 - loss: 0.5662 - val_accuracy: 0.6608 - val_loss: 0.9702\n",
      "Epoch 221/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.6936 - loss: 0.8173\n",
      "Epoch 221: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 204ms/step - accuracy: 0.6936 - loss: 0.8173 - val_accuracy: 0.6702 - val_loss: 0.9252\n",
      "Epoch 222/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:11\u001b[0m 207ms/step - accuracy: 0.6875 - loss: 0.8851\n",
      "Epoch 222: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.8851 - val_accuracy: 0.6706 - val_loss: 0.9238\n",
      "Epoch 223/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.6958 - loss: 0.8156\n",
      "Epoch 223: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 205ms/step - accuracy: 0.6958 - loss: 0.8156 - val_accuracy: 0.6656 - val_loss: 0.9514\n",
      "Epoch 224/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:42\u001b[0m 190ms/step - accuracy: 0.6875 - loss: 1.1809\n",
      "Epoch 224: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 1.1809 - val_accuracy: 0.6700 - val_loss: 0.9470\n",
      "Epoch 225/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.7003 - loss: 0.8127\n",
      "Epoch 225: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 205ms/step - accuracy: 0.7003 - loss: 0.8127 - val_accuracy: 0.6555 - val_loss: 0.9896\n",
      "Epoch 226/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:52\u001b[0m 196ms/step - accuracy: 0.6250 - loss: 0.9944\n",
      "Epoch 226: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.9944 - val_accuracy: 0.6578 - val_loss: 0.9820\n",
      "Epoch 227/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.6969 - loss: 0.8099\n",
      "Epoch 227: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 206ms/step - accuracy: 0.6969 - loss: 0.8099 - val_accuracy: 0.6696 - val_loss: 0.9399\n",
      "Epoch 228/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:42\u001b[0m 190ms/step - accuracy: 0.8125 - loss: 0.7054\n",
      "Epoch 228: val_accuracy did not improve from 0.68011\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.7054 - val_accuracy: 0.6682 - val_loss: 0.9408\n",
      "Epoch 229/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.7035 - loss: 0.8006\n",
      "Epoch 229: val_accuracy improved from 0.68011 to 0.68139, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 203ms/step - accuracy: 0.7035 - loss: 0.8006 - val_accuracy: 0.6814 - val_loss: 0.9304\n",
      "Epoch 230/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:27\u001b[0m 215ms/step - accuracy: 0.6875 - loss: 0.5824\n",
      "Epoch 230: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.6875 - loss: 0.5824 - val_accuracy: 0.6803 - val_loss: 0.9311\n",
      "Epoch 231/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.7018 - loss: 0.8088\n",
      "Epoch 231: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 241ms/step - accuracy: 0.7018 - loss: 0.8088 - val_accuracy: 0.6759 - val_loss: 0.9242\n",
      "Epoch 232/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:53\u001b[0m 197ms/step - accuracy: 0.7500 - loss: 0.9248\n",
      "Epoch 232: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.9248 - val_accuracy: 0.6759 - val_loss: 0.9259\n",
      "Epoch 233/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.6983 - loss: 0.8081\n",
      "Epoch 233: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 201ms/step - accuracy: 0.6983 - loss: 0.8081 - val_accuracy: 0.6783 - val_loss: 0.9343\n",
      "Epoch 234/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:50\u001b[0m 195ms/step - accuracy: 0.7500 - loss: 0.8166\n",
      "Epoch 234: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.8166 - val_accuracy: 0.6778 - val_loss: 0.9352\n",
      "Epoch 235/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.7045 - loss: 0.7927\n",
      "Epoch 235: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 201ms/step - accuracy: 0.7045 - loss: 0.7928 - val_accuracy: 0.6384 - val_loss: 1.0351\n",
      "Epoch 236/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:47\u001b[0m 193ms/step - accuracy: 0.7500 - loss: 0.7540\n",
      "Epoch 236: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.7540 - val_accuracy: 0.6399 - val_loss: 1.0334\n",
      "Epoch 237/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.6995 - loss: 0.8116\n",
      "Epoch 237: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 201ms/step - accuracy: 0.6995 - loss: 0.8116 - val_accuracy: 0.6747 - val_loss: 0.9274\n",
      "Epoch 238/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:41\u001b[0m 190ms/step - accuracy: 0.6875 - loss: 0.7979\n",
      "Epoch 238: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.7979 - val_accuracy: 0.6754 - val_loss: 0.9283\n",
      "Epoch 239/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.7022 - loss: 0.8003\n",
      "Epoch 239: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 200ms/step - accuracy: 0.7022 - loss: 0.8003 - val_accuracy: 0.6010 - val_loss: 1.1248\n",
      "Epoch 240/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:50\u001b[0m 195ms/step - accuracy: 0.8125 - loss: 0.5776\n",
      "Epoch 240: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.5776 - val_accuracy: 0.5994 - val_loss: 1.1247\n",
      "Epoch 241/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.6978 - loss: 0.8077\n",
      "Epoch 241: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 201ms/step - accuracy: 0.6978 - loss: 0.8077 - val_accuracy: 0.6655 - val_loss: 0.9564\n",
      "Epoch 242/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:41\u001b[0m 190ms/step - accuracy: 0.6875 - loss: 0.8548\n",
      "Epoch 242: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.8548 - val_accuracy: 0.6663 - val_loss: 0.9533\n",
      "Epoch 243/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.6993 - loss: 0.7999\n",
      "Epoch 243: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 201ms/step - accuracy: 0.6993 - loss: 0.7999 - val_accuracy: 0.6788 - val_loss: 0.9319\n",
      "Epoch 244/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:36\u001b[0m 187ms/step - accuracy: 0.6875 - loss: 0.6474\n",
      "Epoch 244: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.6474 - val_accuracy: 0.6783 - val_loss: 0.9321\n",
      "Epoch 245/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.7115 - loss: 0.7867\n",
      "Epoch 245: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 201ms/step - accuracy: 0.7115 - loss: 0.7867 - val_accuracy: 0.6693 - val_loss: 0.9451\n",
      "Epoch 246/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:42\u001b[0m 190ms/step - accuracy: 0.6250 - loss: 0.8343\n",
      "Epoch 246: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.8343 - val_accuracy: 0.6675 - val_loss: 0.9460\n",
      "Epoch 247/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.7080 - loss: 0.7964\n",
      "Epoch 247: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 202ms/step - accuracy: 0.7080 - loss: 0.7964 - val_accuracy: 0.6720 - val_loss: 0.9645\n",
      "Epoch 248/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:43\u001b[0m 191ms/step - accuracy: 0.8750 - loss: 0.4501\n",
      "Epoch 248: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8750 - loss: 0.4501 - val_accuracy: 0.6705 - val_loss: 0.9666\n",
      "Epoch 249/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.6980 - loss: 0.8064\n",
      "Epoch 249: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 202ms/step - accuracy: 0.6980 - loss: 0.8064 - val_accuracy: 0.6445 - val_loss: 1.0165\n",
      "Epoch 250/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:43\u001b[0m 191ms/step - accuracy: 0.4375 - loss: 1.2500\n",
      "Epoch 250: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.4375 - loss: 1.2500 - val_accuracy: 0.6464 - val_loss: 1.0075\n",
      "Epoch 251/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.7059 - loss: 0.7890\n",
      "Epoch 251: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 203ms/step - accuracy: 0.7059 - loss: 0.7890 - val_accuracy: 0.6435 - val_loss: 1.0171\n",
      "Epoch 252/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:44\u001b[0m 191ms/step - accuracy: 0.6875 - loss: 0.8101\n",
      "Epoch 252: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.8101 - val_accuracy: 0.6480 - val_loss: 1.0107\n",
      "Epoch 253/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.7032 - loss: 0.7863\n",
      "Epoch 253: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 202ms/step - accuracy: 0.7032 - loss: 0.7863 - val_accuracy: 0.6673 - val_loss: 0.9581\n",
      "Epoch 254/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:05\u001b[0m 203ms/step - accuracy: 0.5000 - loss: 1.0317\n",
      "Epoch 254: val_accuracy did not improve from 0.68139\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 1.0317 - val_accuracy: 0.6638 - val_loss: 0.9660\n",
      "Epoch 255/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.7084 - loss: 0.7857\n",
      "Epoch 255: val_accuracy improved from 0.68139 to 0.68295, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 202ms/step - accuracy: 0.7084 - loss: 0.7857 - val_accuracy: 0.6830 - val_loss: 0.9196\n",
      "Epoch 256/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:47\u001b[0m 193ms/step - accuracy: 0.5000 - loss: 0.8634\n",
      "Epoch 256: val_accuracy improved from 0.68295 to 0.68366, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 0.8634 - val_accuracy: 0.6837 - val_loss: 0.9180\n",
      "Epoch 257/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.7088 - loss: 0.7923\n",
      "Epoch 257: val_accuracy did not improve from 0.68366\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 203ms/step - accuracy: 0.7088 - loss: 0.7923 - val_accuracy: 0.6712 - val_loss: 0.9752\n",
      "Epoch 258/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:43\u001b[0m 191ms/step - accuracy: 0.7500 - loss: 0.6672\n",
      "Epoch 258: val_accuracy did not improve from 0.68366\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.6672 - val_accuracy: 0.6729 - val_loss: 0.9708\n",
      "Epoch 259/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.7139 - loss: 0.7660\n",
      "Epoch 259: val_accuracy did not improve from 0.68366\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 217ms/step - accuracy: 0.7139 - loss: 0.7660 - val_accuracy: 0.6595 - val_loss: 0.9893\n",
      "Epoch 260/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:17\u001b[0m 210ms/step - accuracy: 0.6250 - loss: 0.9589\n",
      "Epoch 260: val_accuracy did not improve from 0.68366\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6250 - loss: 0.9589 - val_accuracy: 0.6577 - val_loss: 0.9929\n",
      "Epoch 261/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.7192 - loss: 0.7678\n",
      "Epoch 261: val_accuracy improved from 0.68366 to 0.68608, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 212ms/step - accuracy: 0.7192 - loss: 0.7678 - val_accuracy: 0.6861 - val_loss: 0.9286\n",
      "Epoch 262/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:50\u001b[0m 195ms/step - accuracy: 0.5625 - loss: 1.5413\n",
      "Epoch 262: val_accuracy improved from 0.68608 to 0.68679, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.5625 - loss: 1.5413 - val_accuracy: 0.6868 - val_loss: 0.9277\n",
      "Epoch 263/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.7112 - loss: 0.7749\n",
      "Epoch 263: val_accuracy did not improve from 0.68679\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 208ms/step - accuracy: 0.7112 - loss: 0.7749 - val_accuracy: 0.6607 - val_loss: 0.9801\n",
      "Epoch 264/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:56\u001b[0m 198ms/step - accuracy: 0.4375 - loss: 1.2565\n",
      "Epoch 264: val_accuracy did not improve from 0.68679\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.4375 - loss: 1.2565 - val_accuracy: 0.6616 - val_loss: 0.9754\n",
      "Epoch 265/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.7124 - loss: 0.7699\n",
      "Epoch 265: val_accuracy improved from 0.68679 to 0.68736, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 208ms/step - accuracy: 0.7124 - loss: 0.7699 - val_accuracy: 0.6874 - val_loss: 0.9301\n",
      "Epoch 266/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:47\u001b[0m 193ms/step - accuracy: 0.8125 - loss: 0.7341\n",
      "Epoch 266: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.7341 - val_accuracy: 0.6869 - val_loss: 0.9304\n",
      "Epoch 267/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.7139 - loss: 0.7661\n",
      "Epoch 267: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 209ms/step - accuracy: 0.7139 - loss: 0.7661 - val_accuracy: 0.6855 - val_loss: 0.9339\n",
      "Epoch 268/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:16\u001b[0m 209ms/step - accuracy: 0.6875 - loss: 0.8397\n",
      "Epoch 268: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.8397 - val_accuracy: 0.6864 - val_loss: 0.9345\n",
      "Epoch 269/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.7092 - loss: 0.7786\n",
      "Epoch 269: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 211ms/step - accuracy: 0.7092 - loss: 0.7786 - val_accuracy: 0.6845 - val_loss: 0.9367\n",
      "Epoch 270/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:54\u001b[0m 197ms/step - accuracy: 0.8750 - loss: 0.4389\n",
      "Epoch 270: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8750 - loss: 0.4389 - val_accuracy: 0.6851 - val_loss: 0.9356\n",
      "Epoch 271/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.7105 - loss: 0.7677\n",
      "Epoch 271: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 209ms/step - accuracy: 0.7105 - loss: 0.7677 - val_accuracy: 0.6837 - val_loss: 0.9410\n",
      "Epoch 272/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:59\u001b[0m 200ms/step - accuracy: 0.8125 - loss: 0.6180\n",
      "Epoch 272: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.6180 - val_accuracy: 0.6828 - val_loss: 0.9412\n",
      "Epoch 273/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.7213 - loss: 0.7557\n",
      "Epoch 273: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 209ms/step - accuracy: 0.7213 - loss: 0.7557 - val_accuracy: 0.6825 - val_loss: 0.9407\n",
      "Epoch 274/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:49\u001b[0m 194ms/step - accuracy: 0.7500 - loss: 0.7445\n",
      "Epoch 274: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.7445 - val_accuracy: 0.6812 - val_loss: 0.9405\n",
      "Epoch 275/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.7147 - loss: 0.7663\n",
      "Epoch 275: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 209ms/step - accuracy: 0.7147 - loss: 0.7663 - val_accuracy: 0.6822 - val_loss: 0.9281\n",
      "Epoch 276/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:56\u001b[0m 198ms/step - accuracy: 0.5625 - loss: 1.0686\n",
      "Epoch 276: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 1.0686 - val_accuracy: 0.6822 - val_loss: 0.9293\n",
      "Epoch 277/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.7160 - loss: 0.7601\n",
      "Epoch 277: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 210ms/step - accuracy: 0.7160 - loss: 0.7601 - val_accuracy: 0.6828 - val_loss: 0.9222\n",
      "Epoch 278/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:27\u001b[0m 215ms/step - accuracy: 0.6250 - loss: 0.7170\n",
      "Epoch 278: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.7170 - val_accuracy: 0.6839 - val_loss: 0.9229\n",
      "Epoch 279/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.7211 - loss: 0.7599\n",
      "Epoch 279: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 210ms/step - accuracy: 0.7211 - loss: 0.7599 - val_accuracy: 0.6727 - val_loss: 0.9670\n",
      "Epoch 280/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:02\u001b[0m 202ms/step - accuracy: 0.5625 - loss: 0.7323\n",
      "Epoch 280: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 0.7323 - val_accuracy: 0.6749 - val_loss: 0.9599\n",
      "Epoch 281/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.7158 - loss: 0.7694\n",
      "Epoch 281: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 212ms/step - accuracy: 0.7158 - loss: 0.7694 - val_accuracy: 0.6825 - val_loss: 0.9386\n",
      "Epoch 282/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:53\u001b[0m 196ms/step - accuracy: 0.9375 - loss: 0.3401\n",
      "Epoch 282: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9375 - loss: 0.3401 - val_accuracy: 0.6828 - val_loss: 0.9383\n",
      "Epoch 283/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.7258 - loss: 0.7376\n",
      "Epoch 283: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 211ms/step - accuracy: 0.7258 - loss: 0.7377 - val_accuracy: 0.6773 - val_loss: 0.9610\n",
      "Epoch 284/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:56\u001b[0m 198ms/step - accuracy: 0.6250 - loss: 0.8477\n",
      "Epoch 284: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.8477 - val_accuracy: 0.6777 - val_loss: 0.9613\n",
      "Epoch 285/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.7194 - loss: 0.7511\n",
      "Epoch 285: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 210ms/step - accuracy: 0.7194 - loss: 0.7511 - val_accuracy: 0.6771 - val_loss: 0.9571\n",
      "Epoch 286/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:50\u001b[0m 195ms/step - accuracy: 0.8125 - loss: 0.8636\n",
      "Epoch 286: val_accuracy did not improve from 0.68736\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.8636 - val_accuracy: 0.6766 - val_loss: 0.9588\n",
      "Epoch 287/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.7188 - loss: 0.7573\n",
      "Epoch 287: val_accuracy improved from 0.68736 to 0.69460, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 211ms/step - accuracy: 0.7188 - loss: 0.7573 - val_accuracy: 0.6946 - val_loss: 0.9140\n",
      "Epoch 288/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:10\u001b[0m 206ms/step - accuracy: 0.7500 - loss: 0.5601\n",
      "Epoch 288: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.5601 - val_accuracy: 0.6933 - val_loss: 0.9158\n",
      "Epoch 289/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.7212 - loss: 0.7468\n",
      "Epoch 289: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 211ms/step - accuracy: 0.7212 - loss: 0.7468 - val_accuracy: 0.6801 - val_loss: 0.9384\n",
      "Epoch 290/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:57\u001b[0m 199ms/step - accuracy: 0.6875 - loss: 0.7266\n",
      "Epoch 290: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.7266 - val_accuracy: 0.6801 - val_loss: 0.9385\n",
      "Epoch 291/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.7142 - loss: 0.7634\n",
      "Epoch 291: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 211ms/step - accuracy: 0.7142 - loss: 0.7634 - val_accuracy: 0.6811 - val_loss: 0.9473\n",
      "Epoch 292/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:15\u001b[0m 209ms/step - accuracy: 0.6250 - loss: 1.0406\n",
      "Epoch 292: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 1.0406 - val_accuracy: 0.6810 - val_loss: 0.9496\n",
      "Epoch 293/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.7111 - loss: 0.7669\n",
      "Epoch 293: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 212ms/step - accuracy: 0.7111 - loss: 0.7669 - val_accuracy: 0.6847 - val_loss: 0.9364\n",
      "Epoch 294/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:54\u001b[0m 197ms/step - accuracy: 0.8750 - loss: 0.5237\n",
      "Epoch 294: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8750 - loss: 0.5237 - val_accuracy: 0.6831 - val_loss: 0.9381\n",
      "Epoch 295/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.7255 - loss: 0.7425\n",
      "Epoch 295: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 211ms/step - accuracy: 0.7255 - loss: 0.7425 - val_accuracy: 0.6795 - val_loss: 0.9497\n",
      "Epoch 296/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:58\u001b[0m 199ms/step - accuracy: 0.6250 - loss: 1.0670\n",
      "Epoch 296: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 1.0670 - val_accuracy: 0.6791 - val_loss: 0.9501\n",
      "Epoch 297/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.7243 - loss: 0.7444\n",
      "Epoch 297: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 211ms/step - accuracy: 0.7243 - loss: 0.7444 - val_accuracy: 0.6547 - val_loss: 1.0182\n",
      "Epoch 298/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:53\u001b[0m 196ms/step - accuracy: 0.4375 - loss: 1.3865\n",
      "Epoch 298: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.4375 - loss: 1.3865 - val_accuracy: 0.6564 - val_loss: 1.0144\n",
      "Epoch 299/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.7207 - loss: 0.7460\n",
      "Epoch 299: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 212ms/step - accuracy: 0.7207 - loss: 0.7460 - val_accuracy: 0.6882 - val_loss: 0.9391\n",
      "Epoch 300/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:14\u001b[0m 208ms/step - accuracy: 0.5625 - loss: 1.2990\n",
      "Epoch 300: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 1.2990 - val_accuracy: 0.6884 - val_loss: 0.9398\n",
      "Epoch 301/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7218 - loss: 0.7400\n",
      "Epoch 301: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 215ms/step - accuracy: 0.7218 - loss: 0.7400 - val_accuracy: 0.6800 - val_loss: 0.9539\n",
      "Epoch 302/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:22\u001b[0m 212ms/step - accuracy: 0.6250 - loss: 1.2621\n",
      "Epoch 302: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 1.2621 - val_accuracy: 0.6794 - val_loss: 0.9554\n",
      "Epoch 303/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.7236 - loss: 0.7373\n",
      "Epoch 303: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 220ms/step - accuracy: 0.7236 - loss: 0.7373 - val_accuracy: 0.6862 - val_loss: 0.9307\n",
      "Epoch 304/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:03\u001b[0m 202ms/step - accuracy: 0.6875 - loss: 0.8286\n",
      "Epoch 304: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.8286 - val_accuracy: 0.6857 - val_loss: 0.9322\n",
      "Epoch 305/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7248 - loss: 0.7436\n",
      "Epoch 305: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 222ms/step - accuracy: 0.7248 - loss: 0.7436 - val_accuracy: 0.6857 - val_loss: 0.9335\n",
      "Epoch 306/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:20\u001b[0m 211ms/step - accuracy: 0.7500 - loss: 1.0992\n",
      "Epoch 306: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 1.0992 - val_accuracy: 0.6861 - val_loss: 0.9329\n",
      "Epoch 307/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.7218 - loss: 0.7396\n",
      "Epoch 307: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 214ms/step - accuracy: 0.7218 - loss: 0.7396 - val_accuracy: 0.6892 - val_loss: 0.9439\n",
      "Epoch 308/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:05\u001b[0m 203ms/step - accuracy: 0.6875 - loss: 0.7374\n",
      "Epoch 308: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.7374 - val_accuracy: 0.6891 - val_loss: 0.9447\n",
      "Epoch 309/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7295 - loss: 0.7269\n",
      "Epoch 309: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 214ms/step - accuracy: 0.7295 - loss: 0.7269 - val_accuracy: 0.6784 - val_loss: 0.9783\n",
      "Epoch 310/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:11\u001b[0m 206ms/step - accuracy: 0.6875 - loss: 1.0533\n",
      "Epoch 310: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 1.0533 - val_accuracy: 0.6781 - val_loss: 0.9776\n",
      "Epoch 311/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.7301 - loss: 0.7317\n",
      "Epoch 311: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 214ms/step - accuracy: 0.7301 - loss: 0.7317 - val_accuracy: 0.6615 - val_loss: 1.0192\n",
      "Epoch 312/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:59\u001b[0m 200ms/step - accuracy: 0.4375 - loss: 1.1019\n",
      "Epoch 312: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.4375 - loss: 1.1019 - val_accuracy: 0.6588 - val_loss: 1.0253\n",
      "Epoch 313/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.7314 - loss: 0.7296\n",
      "Epoch 313: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 214ms/step - accuracy: 0.7313 - loss: 0.7296 - val_accuracy: 0.6884 - val_loss: 0.9237\n",
      "Epoch 314/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:01\u001b[0m 201ms/step - accuracy: 0.6875 - loss: 0.7390\n",
      "Epoch 314: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.7390 - val_accuracy: 0.6886 - val_loss: 0.9242\n",
      "Epoch 315/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.7324 - loss: 0.7234\n",
      "Epoch 315: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 213ms/step - accuracy: 0.7324 - loss: 0.7234 - val_accuracy: 0.6754 - val_loss: 0.9770\n",
      "Epoch 316/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:02\u001b[0m 201ms/step - accuracy: 0.6875 - loss: 1.0154\n",
      "Epoch 316: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 1.0154 - val_accuracy: 0.6723 - val_loss: 0.9858\n",
      "Epoch 317/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.7316 - loss: 0.7292\n",
      "Epoch 317: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 214ms/step - accuracy: 0.7316 - loss: 0.7292 - val_accuracy: 0.6764 - val_loss: 0.9556\n",
      "Epoch 318/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:05\u001b[0m 203ms/step - accuracy: 0.7500 - loss: 0.7160\n",
      "Epoch 318: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.7160 - val_accuracy: 0.6778 - val_loss: 0.9554\n",
      "Epoch 319/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7286 - loss: 0.7291\n",
      "Epoch 319: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 214ms/step - accuracy: 0.7286 - loss: 0.7291 - val_accuracy: 0.6665 - val_loss: 0.9852\n",
      "Epoch 320/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:02\u001b[0m 201ms/step - accuracy: 0.5000 - loss: 1.1030\n",
      "Epoch 320: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 1.1030 - val_accuracy: 0.6663 - val_loss: 0.9842\n",
      "Epoch 321/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7336 - loss: 0.7180\n",
      "Epoch 321: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 214ms/step - accuracy: 0.7336 - loss: 0.7180 - val_accuracy: 0.6801 - val_loss: 0.9510\n",
      "Epoch 322/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:03\u001b[0m 202ms/step - accuracy: 0.7500 - loss: 0.6195\n",
      "Epoch 322: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.6195 - val_accuracy: 0.6788 - val_loss: 0.9528\n",
      "Epoch 323/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7322 - loss: 0.7218\n",
      "Epoch 323: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 215ms/step - accuracy: 0.7322 - loss: 0.7218 - val_accuracy: 0.6794 - val_loss: 0.9811\n",
      "Epoch 324/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:00\u001b[0m 200ms/step - accuracy: 0.5000 - loss: 1.1265\n",
      "Epoch 324: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 1.1265 - val_accuracy: 0.6788 - val_loss: 0.9809\n",
      "Epoch 325/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7293 - loss: 0.7316\n",
      "Epoch 325: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 216ms/step - accuracy: 0.7293 - loss: 0.7316 - val_accuracy: 0.6888 - val_loss: 0.9346\n",
      "Epoch 326/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:55\u001b[0m 197ms/step - accuracy: 0.7500 - loss: 0.7660\n",
      "Epoch 326: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.7660 - val_accuracy: 0.6884 - val_loss: 0.9349\n",
      "Epoch 327/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7377 - loss: 0.7144\n",
      "Epoch 327: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 215ms/step - accuracy: 0.7377 - loss: 0.7144 - val_accuracy: 0.6858 - val_loss: 0.9532\n",
      "Epoch 328/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:07\u001b[0m 204ms/step - accuracy: 0.6250 - loss: 0.9961\n",
      "Epoch 328: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.9961 - val_accuracy: 0.6831 - val_loss: 0.9600\n",
      "Epoch 329/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7397 - loss: 0.7063\n",
      "Epoch 329: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 215ms/step - accuracy: 0.7397 - loss: 0.7063 - val_accuracy: 0.6895 - val_loss: 0.9491\n",
      "Epoch 330/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:04\u001b[0m 202ms/step - accuracy: 0.5000 - loss: 0.9169\n",
      "Epoch 330: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 0.9169 - val_accuracy: 0.6882 - val_loss: 0.9489\n",
      "Epoch 331/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7365 - loss: 0.7128\n",
      "Epoch 331: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 215ms/step - accuracy: 0.7365 - loss: 0.7128 - val_accuracy: 0.6822 - val_loss: 0.9492\n",
      "Epoch 332/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:02\u001b[0m 202ms/step - accuracy: 0.7500 - loss: 0.6285\n",
      "Epoch 332: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.6285 - val_accuracy: 0.6834 - val_loss: 0.9491\n",
      "Epoch 333/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7310 - loss: 0.7148\n",
      "Epoch 333: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 216ms/step - accuracy: 0.7310 - loss: 0.7148 - val_accuracy: 0.6835 - val_loss: 0.9502\n",
      "Epoch 334/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:59\u001b[0m 200ms/step - accuracy: 0.8125 - loss: 0.6666\n",
      "Epoch 334: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.6666 - val_accuracy: 0.6842 - val_loss: 0.9515\n",
      "Epoch 335/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.7365 - loss: 0.7114\n",
      "Epoch 335: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 216ms/step - accuracy: 0.7365 - loss: 0.7114 - val_accuracy: 0.6929 - val_loss: 0.9285\n",
      "Epoch 336/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:21\u001b[0m 212ms/step - accuracy: 0.8125 - loss: 0.3980\n",
      "Epoch 336: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.3980 - val_accuracy: 0.6933 - val_loss: 0.9280\n",
      "Epoch 337/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.7393 - loss: 0.7009\n",
      "Epoch 337: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 217ms/step - accuracy: 0.7393 - loss: 0.7009 - val_accuracy: 0.6459 - val_loss: 1.0966\n",
      "Epoch 338/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:10\u001b[0m 206ms/step - accuracy: 0.7500 - loss: 0.5650\n",
      "Epoch 338: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.5650 - val_accuracy: 0.6447 - val_loss: 1.1012\n",
      "Epoch 339/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.7396 - loss: 0.7029\n",
      "Epoch 339: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 216ms/step - accuracy: 0.7396 - loss: 0.7029 - val_accuracy: 0.6487 - val_loss: 1.0460\n",
      "Epoch 340/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:02\u001b[0m 202ms/step - accuracy: 0.8750 - loss: 0.5124\n",
      "Epoch 340: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8750 - loss: 0.5124 - val_accuracy: 0.6409 - val_loss: 1.0611\n",
      "Epoch 341/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.7365 - loss: 0.7167\n",
      "Epoch 341: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 216ms/step - accuracy: 0.7365 - loss: 0.7167 - val_accuracy: 0.6834 - val_loss: 0.9887\n",
      "Epoch 342/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:14\u001b[0m 208ms/step - accuracy: 0.8125 - loss: 0.5657\n",
      "Epoch 342: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.5657 - val_accuracy: 0.6834 - val_loss: 0.9899\n",
      "Epoch 343/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.7371 - loss: 0.7095\n",
      "Epoch 343: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 217ms/step - accuracy: 0.7371 - loss: 0.7095 - val_accuracy: 0.6570 - val_loss: 1.0242\n",
      "Epoch 344/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:04\u001b[0m 203ms/step - accuracy: 0.7500 - loss: 0.6250\n",
      "Epoch 344: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.6250 - val_accuracy: 0.6553 - val_loss: 1.0301\n",
      "Epoch 345/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.7371 - loss: 0.7117\n",
      "Epoch 345: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 218ms/step - accuracy: 0.7371 - loss: 0.7117 - val_accuracy: 0.6800 - val_loss: 0.9755\n",
      "Epoch 346/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:21\u001b[0m 212ms/step - accuracy: 0.6875 - loss: 0.8563\n",
      "Epoch 346: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.8563 - val_accuracy: 0.6790 - val_loss: 0.9762\n",
      "Epoch 347/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7364 - loss: 0.7132\n",
      "Epoch 347: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 218ms/step - accuracy: 0.7364 - loss: 0.7132 - val_accuracy: 0.6720 - val_loss: 0.9822\n",
      "Epoch 348/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:13\u001b[0m 208ms/step - accuracy: 0.6875 - loss: 0.9593\n",
      "Epoch 348: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.9593 - val_accuracy: 0.6693 - val_loss: 0.9892\n",
      "Epoch 349/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7415 - loss: 0.6999\n",
      "Epoch 349: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 219ms/step - accuracy: 0.7415 - loss: 0.6999 - val_accuracy: 0.6753 - val_loss: 0.9919\n",
      "Epoch 350/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:21\u001b[0m 212ms/step - accuracy: 0.6875 - loss: 0.8131\n",
      "Epoch 350: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.8131 - val_accuracy: 0.6756 - val_loss: 0.9907\n",
      "Epoch 351/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7425 - loss: 0.7040\n",
      "Epoch 351: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 218ms/step - accuracy: 0.7425 - loss: 0.7040 - val_accuracy: 0.6793 - val_loss: 0.9552\n",
      "Epoch 352/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:08\u001b[0m 205ms/step - accuracy: 0.6250 - loss: 0.8696\n",
      "Epoch 352: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.8696 - val_accuracy: 0.6788 - val_loss: 0.9548\n",
      "Epoch 353/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7442 - loss: 0.6891\n",
      "Epoch 353: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 218ms/step - accuracy: 0.7442 - loss: 0.6891 - val_accuracy: 0.6800 - val_loss: 0.9664\n",
      "Epoch 354/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:19\u001b[0m 211ms/step - accuracy: 0.8750 - loss: 0.4630\n",
      "Epoch 354: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8750 - loss: 0.4630 - val_accuracy: 0.6808 - val_loss: 0.9657\n",
      "Epoch 355/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7446 - loss: 0.6911\n",
      "Epoch 355: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 218ms/step - accuracy: 0.7446 - loss: 0.6911 - val_accuracy: 0.6783 - val_loss: 1.0122\n",
      "Epoch 356/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:01\u001b[0m 201ms/step - accuracy: 0.7500 - loss: 0.6100\n",
      "Epoch 356: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.6100 - val_accuracy: 0.6804 - val_loss: 1.0070\n",
      "Epoch 357/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7446 - loss: 0.6920\n",
      "Epoch 357: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 219ms/step - accuracy: 0.7446 - loss: 0.6920 - val_accuracy: 0.6855 - val_loss: 0.9410\n",
      "Epoch 358/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:13\u001b[0m 208ms/step - accuracy: 0.8125 - loss: 0.6043\n",
      "Epoch 358: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.6043 - val_accuracy: 0.6864 - val_loss: 0.9404\n",
      "Epoch 359/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.7411 - loss: 0.6964\n",
      "Epoch 359: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 220ms/step - accuracy: 0.7411 - loss: 0.6964 - val_accuracy: 0.6849 - val_loss: 0.9468\n",
      "Epoch 360/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:04\u001b[0m 203ms/step - accuracy: 0.7500 - loss: 0.7344\n",
      "Epoch 360: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.7344 - val_accuracy: 0.6851 - val_loss: 0.9468\n",
      "Epoch 361/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7443 - loss: 0.6886\n",
      "Epoch 361: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 220ms/step - accuracy: 0.7443 - loss: 0.6886 - val_accuracy: 0.6871 - val_loss: 0.9419\n",
      "Epoch 362/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:21\u001b[0m 212ms/step - accuracy: 0.8125 - loss: 0.6158\n",
      "Epoch 362: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.6158 - val_accuracy: 0.6859 - val_loss: 0.9419\n",
      "Epoch 363/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.7447 - loss: 0.6827\n",
      "Epoch 363: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 220ms/step - accuracy: 0.7447 - loss: 0.6827 - val_accuracy: 0.6768 - val_loss: 0.9838\n",
      "Epoch 364/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:19\u001b[0m 211ms/step - accuracy: 0.9375 - loss: 0.5246\n",
      "Epoch 364: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9375 - loss: 0.5246 - val_accuracy: 0.6761 - val_loss: 0.9845\n",
      "Epoch 365/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.7430 - loss: 0.6887\n",
      "Epoch 365: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 221ms/step - accuracy: 0.7430 - loss: 0.6887 - val_accuracy: 0.6815 - val_loss: 0.9653\n",
      "Epoch 366/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:39\u001b[0m 222ms/step - accuracy: 0.6875 - loss: 0.7068\n",
      "Epoch 366: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.7068 - val_accuracy: 0.6798 - val_loss: 0.9660\n",
      "Epoch 367/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.7451 - loss: 0.6883\n",
      "Epoch 367: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 221ms/step - accuracy: 0.7451 - loss: 0.6883 - val_accuracy: 0.6812 - val_loss: 0.9670\n",
      "Epoch 368/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:14\u001b[0m 208ms/step - accuracy: 0.8125 - loss: 0.5467\n",
      "Epoch 368: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.5467 - val_accuracy: 0.6828 - val_loss: 0.9642\n",
      "Epoch 369/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.7436 - loss: 0.6954\n",
      "Epoch 369: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m398s\u001b[0m 221ms/step - accuracy: 0.7436 - loss: 0.6954 - val_accuracy: 0.6784 - val_loss: 0.9800\n",
      "Epoch 370/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:06\u001b[0m 204ms/step - accuracy: 0.8125 - loss: 0.5103\n",
      "Epoch 370: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.5103 - val_accuracy: 0.6790 - val_loss: 0.9777\n",
      "Epoch 371/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.7496 - loss: 0.6867\n",
      "Epoch 371: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m398s\u001b[0m 221ms/step - accuracy: 0.7496 - loss: 0.6867 - val_accuracy: 0.6621 - val_loss: 1.0206\n",
      "Epoch 372/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:20\u001b[0m 211ms/step - accuracy: 0.6875 - loss: 0.9021\n",
      "Epoch 372: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.9021 - val_accuracy: 0.6616 - val_loss: 1.0200\n",
      "Epoch 373/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7467 - loss: 0.6773\n",
      "Epoch 373: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 222ms/step - accuracy: 0.7467 - loss: 0.6773 - val_accuracy: 0.6824 - val_loss: 0.9718\n",
      "Epoch 374/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:18\u001b[0m 210ms/step - accuracy: 1.0000 - loss: 0.2445\n",
      "Epoch 374: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.2445 - val_accuracy: 0.6838 - val_loss: 0.9709\n",
      "Epoch 375/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.7476 - loss: 0.6760\n",
      "Epoch 375: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 222ms/step - accuracy: 0.7476 - loss: 0.6760 - val_accuracy: 0.6589 - val_loss: 1.0445\n",
      "Epoch 376/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:15\u001b[0m 209ms/step - accuracy: 0.8125 - loss: 0.5887\n",
      "Epoch 376: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.5887 - val_accuracy: 0.6575 - val_loss: 1.0465\n",
      "Epoch 377/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7406 - loss: 0.6909\n",
      "Epoch 377: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 222ms/step - accuracy: 0.7406 - loss: 0.6909 - val_accuracy: 0.6709 - val_loss: 1.0223\n",
      "Epoch 378/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:10\u001b[0m 206ms/step - accuracy: 0.8125 - loss: 0.6709\n",
      "Epoch 378: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.6709 - val_accuracy: 0.6717 - val_loss: 1.0201\n",
      "Epoch 379/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7460 - loss: 0.6870\n",
      "Epoch 379: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 222ms/step - accuracy: 0.7460 - loss: 0.6870 - val_accuracy: 0.6835 - val_loss: 0.9529\n",
      "Epoch 380/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:26\u001b[0m 215ms/step - accuracy: 0.5625 - loss: 0.7575\n",
      "Epoch 380: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 0.7575 - val_accuracy: 0.6851 - val_loss: 0.9554\n",
      "Epoch 381/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7497 - loss: 0.6733\n",
      "Epoch 381: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 222ms/step - accuracy: 0.7497 - loss: 0.6733 - val_accuracy: 0.6680 - val_loss: 1.0100\n",
      "Epoch 382/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:11\u001b[0m 206ms/step - accuracy: 0.6875 - loss: 0.5923\n",
      "Epoch 382: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.5923 - val_accuracy: 0.6666 - val_loss: 1.0216\n",
      "Epoch 383/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7500 - loss: 0.6881\n",
      "Epoch 383: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 222ms/step - accuracy: 0.7500 - loss: 0.6881 - val_accuracy: 0.6892 - val_loss: 0.9573\n",
      "Epoch 384/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:14\u001b[0m 208ms/step - accuracy: 0.7500 - loss: 0.5639\n",
      "Epoch 384: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.5639 - val_accuracy: 0.6895 - val_loss: 0.9569\n",
      "Epoch 385/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7467 - loss: 0.6819\n",
      "Epoch 385: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 223ms/step - accuracy: 0.7467 - loss: 0.6819 - val_accuracy: 0.6893 - val_loss: 0.9634\n",
      "Epoch 386/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:37\u001b[0m 221ms/step - accuracy: 0.8750 - loss: 0.6393\n",
      "Epoch 386: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8750 - loss: 0.6393 - val_accuracy: 0.6895 - val_loss: 0.9633\n",
      "Epoch 387/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.7540 - loss: 0.6688\n",
      "Epoch 387: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 228ms/step - accuracy: 0.7540 - loss: 0.6688 - val_accuracy: 0.6838 - val_loss: 0.9724\n",
      "Epoch 388/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:21\u001b[0m 212ms/step - accuracy: 0.8125 - loss: 0.3322\n",
      "Epoch 388: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.3322 - val_accuracy: 0.6841 - val_loss: 0.9678\n",
      "Epoch 389/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.7515 - loss: 0.6696\n",
      "Epoch 389: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 225ms/step - accuracy: 0.7515 - loss: 0.6696 - val_accuracy: 0.6820 - val_loss: 0.9847\n",
      "Epoch 390/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:26\u001b[0m 215ms/step - accuracy: 0.9375 - loss: 0.4647\n",
      "Epoch 390: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9375 - loss: 0.4647 - val_accuracy: 0.6817 - val_loss: 0.9812\n",
      "Epoch 391/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.7511 - loss: 0.6743\n",
      "Epoch 391: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 225ms/step - accuracy: 0.7511 - loss: 0.6743 - val_accuracy: 0.6884 - val_loss: 0.9866\n",
      "Epoch 392/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:25\u001b[0m 214ms/step - accuracy: 0.8125 - loss: 0.5493\n",
      "Epoch 392: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.5493 - val_accuracy: 0.6886 - val_loss: 0.9894\n",
      "Epoch 393/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.7531 - loss: 0.6674\n",
      "Epoch 393: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 227ms/step - accuracy: 0.7531 - loss: 0.6674 - val_accuracy: 0.6932 - val_loss: 0.9646\n",
      "Epoch 394/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:36\u001b[0m 220ms/step - accuracy: 0.8125 - loss: 0.5883\n",
      "Epoch 394: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.5883 - val_accuracy: 0.6928 - val_loss: 0.9669\n",
      "Epoch 395/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.7538 - loss: 0.6670\n",
      "Epoch 395: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 224ms/step - accuracy: 0.7538 - loss: 0.6670 - val_accuracy: 0.6851 - val_loss: 0.9639\n",
      "Epoch 396/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:17\u001b[0m 210ms/step - accuracy: 0.6875 - loss: 0.6831\n",
      "Epoch 396: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.6831 - val_accuracy: 0.6852 - val_loss: 0.9643\n",
      "Epoch 397/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.7552 - loss: 0.6574\n",
      "Epoch 397: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 224ms/step - accuracy: 0.7552 - loss: 0.6574 - val_accuracy: 0.6734 - val_loss: 1.0028\n",
      "Epoch 398/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:25\u001b[0m 214ms/step - accuracy: 0.6875 - loss: 0.8658\n",
      "Epoch 398: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.8658 - val_accuracy: 0.6727 - val_loss: 1.0058\n",
      "Epoch 399/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.7551 - loss: 0.6623\n",
      "Epoch 399: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 226ms/step - accuracy: 0.7551 - loss: 0.6623 - val_accuracy: 0.6764 - val_loss: 0.9980\n",
      "Epoch 400/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:16\u001b[0m 209ms/step - accuracy: 0.5625 - loss: 1.5298\n",
      "Epoch 400: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 1.5298 - val_accuracy: 0.6746 - val_loss: 1.0034\n",
      "Epoch 401/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.7539 - loss: 0.6658\n",
      "Epoch 401: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 224ms/step - accuracy: 0.7539 - loss: 0.6658 - val_accuracy: 0.6714 - val_loss: 1.0208\n",
      "Epoch 402/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:18\u001b[0m 211ms/step - accuracy: 0.7500 - loss: 0.8043\n",
      "Epoch 402: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.8043 - val_accuracy: 0.6709 - val_loss: 1.0230\n",
      "Epoch 403/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.7598 - loss: 0.6511\n",
      "Epoch 403: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 225ms/step - accuracy: 0.7598 - loss: 0.6511 - val_accuracy: 0.6624 - val_loss: 1.0502\n",
      "Epoch 404/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:22\u001b[0m 212ms/step - accuracy: 0.8125 - loss: 0.4427\n",
      "Epoch 404: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.4427 - val_accuracy: 0.6611 - val_loss: 1.0571\n",
      "Epoch 405/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.7476 - loss: 0.6741\n",
      "Epoch 405: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 225ms/step - accuracy: 0.7476 - loss: 0.6741 - val_accuracy: 0.6895 - val_loss: 0.9678\n",
      "Epoch 406/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:33\u001b[0m 252ms/step - accuracy: 0.6250 - loss: 0.8208\n",
      "Epoch 406: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6250 - loss: 0.8208 - val_accuracy: 0.6901 - val_loss: 0.9667\n",
      "Epoch 407/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.7586 - loss: 0.6450\n",
      "Epoch 407: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 225ms/step - accuracy: 0.7586 - loss: 0.6450 - val_accuracy: 0.6844 - val_loss: 0.9811\n",
      "Epoch 408/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:23\u001b[0m 213ms/step - accuracy: 0.7500 - loss: 0.6734\n",
      "Epoch 408: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.6734 - val_accuracy: 0.6839 - val_loss: 0.9830\n",
      "Epoch 409/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.7615 - loss: 0.6467\n",
      "Epoch 409: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 226ms/step - accuracy: 0.7615 - loss: 0.6467 - val_accuracy: 0.6838 - val_loss: 0.9885\n",
      "Epoch 410/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:24\u001b[0m 214ms/step - accuracy: 0.8125 - loss: 0.7030\n",
      "Epoch 410: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.7030 - val_accuracy: 0.6822 - val_loss: 0.9908\n",
      "Epoch 411/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.7573 - loss: 0.6558\n",
      "Epoch 411: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 225ms/step - accuracy: 0.7573 - loss: 0.6558 - val_accuracy: 0.6750 - val_loss: 1.0194\n",
      "Epoch 412/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:16\u001b[0m 209ms/step - accuracy: 0.9375 - loss: 0.3573\n",
      "Epoch 412: val_accuracy did not improve from 0.69460\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.3573 - val_accuracy: 0.6736 - val_loss: 1.0218\n",
      "Epoch 413/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.7573 - loss: 0.6554\n",
      "Epoch 413: val_accuracy improved from 0.69460 to 0.69673, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 227ms/step - accuracy: 0.7573 - loss: 0.6554 - val_accuracy: 0.6967 - val_loss: 0.9527\n",
      "Epoch 414/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:25\u001b[0m 214ms/step - accuracy: 0.6250 - loss: 0.8729\n",
      "Epoch 414: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.8729 - val_accuracy: 0.6966 - val_loss: 0.9520\n",
      "Epoch 415/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.7579 - loss: 0.6589\n",
      "Epoch 415: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 227ms/step - accuracy: 0.7579 - loss: 0.6590 - val_accuracy: 0.6530 - val_loss: 1.0506\n",
      "Epoch 416/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:29\u001b[0m 216ms/step - accuracy: 0.7500 - loss: 0.5319\n",
      "Epoch 416: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.5319 - val_accuracy: 0.6547 - val_loss: 1.0511\n",
      "Epoch 417/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.7567 - loss: 0.6584\n",
      "Epoch 417: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 227ms/step - accuracy: 0.7567 - loss: 0.6584 - val_accuracy: 0.6607 - val_loss: 1.0395\n",
      "Epoch 418/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:30\u001b[0m 217ms/step - accuracy: 0.7500 - loss: 0.8036\n",
      "Epoch 418: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.8036 - val_accuracy: 0.6615 - val_loss: 1.0376\n",
      "Epoch 419/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.7565 - loss: 0.6574\n",
      "Epoch 419: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 253ms/step - accuracy: 0.7565 - loss: 0.6574 - val_accuracy: 0.6766 - val_loss: 1.0024\n",
      "Epoch 420/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:47\u001b[0m 226ms/step - accuracy: 0.8125 - loss: 0.4541\n",
      "Epoch 420: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.4541 - val_accuracy: 0.6771 - val_loss: 1.0026\n",
      "Epoch 421/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.7617 - loss: 0.6449\n",
      "Epoch 421: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 237ms/step - accuracy: 0.7617 - loss: 0.6449 - val_accuracy: 0.6912 - val_loss: 0.9857\n",
      "Epoch 422/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:15\u001b[0m 209ms/step - accuracy: 0.8125 - loss: 0.5023\n",
      "Epoch 422: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.5023 - val_accuracy: 0.6908 - val_loss: 0.9851\n",
      "Epoch 423/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.7567 - loss: 0.6622\n",
      "Epoch 423: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 228ms/step - accuracy: 0.7567 - loss: 0.6622 - val_accuracy: 0.6933 - val_loss: 0.9657\n",
      "Epoch 424/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:31\u001b[0m 218ms/step - accuracy: 0.7500 - loss: 0.6443\n",
      "Epoch 424: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.6443 - val_accuracy: 0.6939 - val_loss: 0.9639\n",
      "Epoch 425/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.7621 - loss: 0.6434\n",
      "Epoch 425: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 229ms/step - accuracy: 0.7621 - loss: 0.6434 - val_accuracy: 0.6801 - val_loss: 0.9870\n",
      "Epoch 426/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:31\u001b[0m 217ms/step - accuracy: 0.8750 - loss: 0.4959\n",
      "Epoch 426: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8750 - loss: 0.4959 - val_accuracy: 0.6793 - val_loss: 0.9905\n",
      "Epoch 427/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.7594 - loss: 0.6437\n",
      "Epoch 427: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 228ms/step - accuracy: 0.7594 - loss: 0.6437 - val_accuracy: 0.6839 - val_loss: 1.0221\n",
      "Epoch 428/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:34\u001b[0m 219ms/step - accuracy: 0.6250 - loss: 0.8773\n",
      "Epoch 428: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.6250 - loss: 0.8773 - val_accuracy: 0.6842 - val_loss: 1.0232\n",
      "Epoch 429/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.7648 - loss: 0.6290\n",
      "Epoch 429: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 229ms/step - accuracy: 0.7648 - loss: 0.6290 - val_accuracy: 0.6929 - val_loss: 1.0005\n",
      "Epoch 430/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:22\u001b[0m 213ms/step - accuracy: 0.8125 - loss: 0.4727\n",
      "Epoch 430: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.4727 - val_accuracy: 0.6923 - val_loss: 0.9976\n",
      "Epoch 431/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.7573 - loss: 0.6573\n",
      "Epoch 431: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 229ms/step - accuracy: 0.7573 - loss: 0.6573 - val_accuracy: 0.6808 - val_loss: 0.9941\n",
      "Epoch 432/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:21\u001b[0m 212ms/step - accuracy: 0.8750 - loss: 0.3213\n",
      "Epoch 432: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8750 - loss: 0.3213 - val_accuracy: 0.6793 - val_loss: 0.9957\n",
      "Epoch 433/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.7640 - loss: 0.6392\n",
      "Epoch 433: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 230ms/step - accuracy: 0.7640 - loss: 0.6392 - val_accuracy: 0.6483 - val_loss: 1.1207\n",
      "Epoch 434/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:44\u001b[0m 225ms/step - accuracy: 0.6875 - loss: 0.6482\n",
      "Epoch 434: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.6482 - val_accuracy: 0.6467 - val_loss: 1.1239\n",
      "Epoch 435/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.7626 - loss: 0.6464\n",
      "Epoch 435: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 231ms/step - accuracy: 0.7626 - loss: 0.6464 - val_accuracy: 0.6956 - val_loss: 0.9583\n",
      "Epoch 436/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:27\u001b[0m 215ms/step - accuracy: 0.8125 - loss: 0.8090\n",
      "Epoch 436: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.8090 - val_accuracy: 0.6946 - val_loss: 0.9588\n",
      "Epoch 437/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.7679 - loss: 0.6357\n",
      "Epoch 437: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 231ms/step - accuracy: 0.7679 - loss: 0.6357 - val_accuracy: 0.6741 - val_loss: 1.0204\n",
      "Epoch 438/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:33\u001b[0m 218ms/step - accuracy: 0.8125 - loss: 0.3317\n",
      "Epoch 438: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.3317 - val_accuracy: 0.6740 - val_loss: 1.0162\n",
      "Epoch 439/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.7645 - loss: 0.6344\n",
      "Epoch 439: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 231ms/step - accuracy: 0.7645 - loss: 0.6344 - val_accuracy: 0.6787 - val_loss: 1.0312\n",
      "Epoch 440/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:30\u001b[0m 217ms/step - accuracy: 0.7500 - loss: 0.5992\n",
      "Epoch 440: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.5992 - val_accuracy: 0.6815 - val_loss: 1.0271\n",
      "Epoch 441/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.7620 - loss: 0.6390\n",
      "Epoch 441: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 231ms/step - accuracy: 0.7620 - loss: 0.6390 - val_accuracy: 0.6501 - val_loss: 1.0919\n",
      "Epoch 442/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:33\u001b[0m 218ms/step - accuracy: 0.7500 - loss: 0.7475\n",
      "Epoch 442: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.7475 - val_accuracy: 0.6470 - val_loss: 1.0982\n",
      "Epoch 443/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.7634 - loss: 0.6419\n",
      "Epoch 443: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 232ms/step - accuracy: 0.7634 - loss: 0.6419 - val_accuracy: 0.6923 - val_loss: 0.9656\n",
      "Epoch 444/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:32\u001b[0m 218ms/step - accuracy: 0.8125 - loss: 0.6340\n",
      "Epoch 444: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.6340 - val_accuracy: 0.6925 - val_loss: 0.9652\n",
      "Epoch 445/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.7626 - loss: 0.6421\n",
      "Epoch 445: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 233ms/step - accuracy: 0.7626 - loss: 0.6421 - val_accuracy: 0.6945 - val_loss: 0.9731\n",
      "Epoch 446/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:27\u001b[0m 249ms/step - accuracy: 0.8125 - loss: 0.6975\n",
      "Epoch 446: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.6975 - val_accuracy: 0.6945 - val_loss: 0.9738\n",
      "Epoch 447/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.7662 - loss: 0.6324\n",
      "Epoch 447: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 233ms/step - accuracy: 0.7662 - loss: 0.6324 - val_accuracy: 0.6878 - val_loss: 0.9973\n",
      "Epoch 448/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:34\u001b[0m 219ms/step - accuracy: 0.8750 - loss: 0.4291\n",
      "Epoch 448: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8750 - loss: 0.4291 - val_accuracy: 0.6865 - val_loss: 0.9982\n",
      "Epoch 449/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.7671 - loss: 0.6288\n",
      "Epoch 449: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 232ms/step - accuracy: 0.7671 - loss: 0.6288 - val_accuracy: 0.6855 - val_loss: 1.0139\n",
      "Epoch 450/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:30\u001b[0m 217ms/step - accuracy: 0.5000 - loss: 1.0927\n",
      "Epoch 450: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.5000 - loss: 1.0927 - val_accuracy: 0.6848 - val_loss: 1.0157\n",
      "Epoch 451/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.7681 - loss: 0.6253\n",
      "Epoch 451: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 232ms/step - accuracy: 0.7681 - loss: 0.6253 - val_accuracy: 0.6720 - val_loss: 1.0217\n",
      "Epoch 452/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:37\u001b[0m 221ms/step - accuracy: 0.7500 - loss: 0.7863\n",
      "Epoch 452: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.7863 - val_accuracy: 0.6734 - val_loss: 1.0198\n",
      "Epoch 453/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.7684 - loss: 0.6266\n",
      "Epoch 453: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 233ms/step - accuracy: 0.7684 - loss: 0.6266 - val_accuracy: 0.6793 - val_loss: 1.0096\n",
      "Epoch 454/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:32\u001b[0m 218ms/step - accuracy: 0.9375 - loss: 0.2577\n",
      "Epoch 454: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.2577 - val_accuracy: 0.6821 - val_loss: 1.0006\n",
      "Epoch 455/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.7681 - loss: 0.6342\n",
      "Epoch 455: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 234ms/step - accuracy: 0.7681 - loss: 0.6342 - val_accuracy: 0.6805 - val_loss: 1.0094\n",
      "Epoch 456/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:56\u001b[0m 231ms/step - accuracy: 0.8750 - loss: 0.3638\n",
      "Epoch 456: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8750 - loss: 0.3638 - val_accuracy: 0.6841 - val_loss: 1.0031\n",
      "Epoch 457/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.7702 - loss: 0.6249\n",
      "Epoch 457: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 233ms/step - accuracy: 0.7702 - loss: 0.6249 - val_accuracy: 0.6616 - val_loss: 1.0777\n",
      "Epoch 458/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:33\u001b[0m 218ms/step - accuracy: 0.7500 - loss: 0.4862\n",
      "Epoch 458: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.4862 - val_accuracy: 0.6598 - val_loss: 1.0827\n",
      "Epoch 459/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.7690 - loss: 0.6240\n",
      "Epoch 459: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 234ms/step - accuracy: 0.7690 - loss: 0.6240 - val_accuracy: 0.6868 - val_loss: 1.0143\n",
      "Epoch 460/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:33\u001b[0m 219ms/step - accuracy: 0.8750 - loss: 0.4647\n",
      "Epoch 460: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8750 - loss: 0.4647 - val_accuracy: 0.6866 - val_loss: 1.0152\n",
      "Epoch 461/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.7695 - loss: 0.6251\n",
      "Epoch 461: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 235ms/step - accuracy: 0.7695 - loss: 0.6251 - val_accuracy: 0.6618 - val_loss: 1.0690\n",
      "Epoch 462/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:37\u001b[0m 221ms/step - accuracy: 0.8750 - loss: 0.5085\n",
      "Epoch 462: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8750 - loss: 0.5085 - val_accuracy: 0.6625 - val_loss: 1.0570\n",
      "Epoch 463/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.7703 - loss: 0.6241\n",
      "Epoch 463: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 234ms/step - accuracy: 0.7703 - loss: 0.6241 - val_accuracy: 0.6473 - val_loss: 1.1368\n",
      "Epoch 464/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:42\u001b[0m 224ms/step - accuracy: 0.8125 - loss: 0.5071\n",
      "Epoch 464: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.5071 - val_accuracy: 0.6479 - val_loss: 1.1352\n",
      "Epoch 465/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.7690 - loss: 0.6185\n",
      "Epoch 465: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 234ms/step - accuracy: 0.7690 - loss: 0.6185 - val_accuracy: 0.6930 - val_loss: 0.9926\n",
      "Epoch 466/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:35\u001b[0m 220ms/step - accuracy: 0.8750 - loss: 0.4176\n",
      "Epoch 466: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8750 - loss: 0.4176 - val_accuracy: 0.6933 - val_loss: 0.9949\n",
      "Epoch 467/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.7726 - loss: 0.6195\n",
      "Epoch 467: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 235ms/step - accuracy: 0.7726 - loss: 0.6195 - val_accuracy: 0.6942 - val_loss: 0.9808\n",
      "Epoch 468/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:04\u001b[0m 236ms/step - accuracy: 0.6875 - loss: 0.7799\n",
      "Epoch 468: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.7799 - val_accuracy: 0.6939 - val_loss: 0.9821\n",
      "Epoch 469/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.7677 - loss: 0.6200\n",
      "Epoch 469: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 236ms/step - accuracy: 0.7677 - loss: 0.6200 - val_accuracy: 0.6751 - val_loss: 1.0482\n",
      "Epoch 470/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:30\u001b[0m 217ms/step - accuracy: 0.6875 - loss: 0.5192\n",
      "Epoch 470: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.5192 - val_accuracy: 0.6757 - val_loss: 1.0482\n",
      "Epoch 471/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.7684 - loss: 0.6257\n",
      "Epoch 471: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 236ms/step - accuracy: 0.7684 - loss: 0.6257 - val_accuracy: 0.6913 - val_loss: 1.0027\n",
      "Epoch 472/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:56\u001b[0m 232ms/step - accuracy: 0.8125 - loss: 0.4772\n",
      "Epoch 472: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.4772 - val_accuracy: 0.6926 - val_loss: 1.0026\n",
      "Epoch 473/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.7667 - loss: 0.6193\n",
      "Epoch 473: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 237ms/step - accuracy: 0.7667 - loss: 0.6193 - val_accuracy: 0.6946 - val_loss: 0.9762\n",
      "Epoch 474/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:49\u001b[0m 228ms/step - accuracy: 0.7500 - loss: 0.6737\n",
      "Epoch 474: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.6737 - val_accuracy: 0.6949 - val_loss: 0.9750\n",
      "Epoch 475/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.7687 - loss: 0.6174\n",
      "Epoch 475: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 236ms/step - accuracy: 0.7687 - loss: 0.6174 - val_accuracy: 0.6411 - val_loss: 1.1660\n",
      "Epoch 476/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:30\u001b[0m 217ms/step - accuracy: 0.7500 - loss: 0.8732\n",
      "Epoch 476: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.8732 - val_accuracy: 0.6391 - val_loss: 1.1713\n",
      "Epoch 477/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.7706 - loss: 0.6232\n",
      "Epoch 477: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 237ms/step - accuracy: 0.7707 - loss: 0.6232 - val_accuracy: 0.6776 - val_loss: 1.0371\n",
      "Epoch 478/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:51\u001b[0m 229ms/step - accuracy: 0.6875 - loss: 0.6589\n",
      "Epoch 478: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.6589 - val_accuracy: 0.6784 - val_loss: 1.0363\n",
      "Epoch 479/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.7725 - loss: 0.6134\n",
      "Epoch 479: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 243ms/step - accuracy: 0.7725 - loss: 0.6134 - val_accuracy: 0.6855 - val_loss: 1.0256\n",
      "Epoch 480/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:44\u001b[0m 225ms/step - accuracy: 0.6875 - loss: 0.5662\n",
      "Epoch 480: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.5662 - val_accuracy: 0.6848 - val_loss: 1.0260\n",
      "Epoch 481/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.7671 - loss: 0.6277\n",
      "Epoch 481: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 236ms/step - accuracy: 0.7671 - loss: 0.6277 - val_accuracy: 0.6869 - val_loss: 1.0296\n",
      "Epoch 482/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:30\u001b[0m 217ms/step - accuracy: 0.6875 - loss: 0.7060\n",
      "Epoch 482: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.7060 - val_accuracy: 0.6862 - val_loss: 1.0346\n",
      "Epoch 483/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.7774 - loss: 0.5957\n",
      "Epoch 483: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 237ms/step - accuracy: 0.7774 - loss: 0.5957 - val_accuracy: 0.6683 - val_loss: 1.0416\n",
      "Epoch 484/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:38\u001b[0m 221ms/step - accuracy: 0.7500 - loss: 0.4998\n",
      "Epoch 484: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.4998 - val_accuracy: 0.6702 - val_loss: 1.0368\n",
      "Epoch 485/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.7744 - loss: 0.6077\n",
      "Epoch 485: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 237ms/step - accuracy: 0.7744 - loss: 0.6077 - val_accuracy: 0.6716 - val_loss: 1.0639\n",
      "Epoch 486/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:40\u001b[0m 222ms/step - accuracy: 0.7500 - loss: 0.4183\n",
      "Epoch 486: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.4183 - val_accuracy: 0.6692 - val_loss: 1.0707\n",
      "Epoch 487/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.7758 - loss: 0.6130\n",
      "Epoch 487: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 238ms/step - accuracy: 0.7758 - loss: 0.6130 - val_accuracy: 0.6876 - val_loss: 0.9882\n",
      "Epoch 488/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:57\u001b[0m 232ms/step - accuracy: 0.9375 - loss: 0.2466\n",
      "Epoch 488: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.2466 - val_accuracy: 0.6876 - val_loss: 0.9897\n",
      "Epoch 489/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.7714 - loss: 0.6158\n",
      "Epoch 489: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 238ms/step - accuracy: 0.7714 - loss: 0.6158 - val_accuracy: 0.6736 - val_loss: 1.0647\n",
      "Epoch 490/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:37\u001b[0m 221ms/step - accuracy: 0.7500 - loss: 0.9471\n",
      "Epoch 490: val_accuracy did not improve from 0.69673\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.9471 - val_accuracy: 0.6760 - val_loss: 1.0596\n",
      "Epoch 491/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.7738 - loss: 0.6107\n",
      "Epoch 491: val_accuracy improved from 0.69673 to 0.69787, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 239ms/step - accuracy: 0.7738 - loss: 0.6107 - val_accuracy: 0.6979 - val_loss: 0.9790\n",
      "Epoch 492/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:41\u001b[0m 223ms/step - accuracy: 0.8125 - loss: 0.4709\n",
      "Epoch 492: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.4709 - val_accuracy: 0.6972 - val_loss: 0.9804\n",
      "Epoch 493/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.7758 - loss: 0.6013\n",
      "Epoch 493: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 239ms/step - accuracy: 0.7758 - loss: 0.6013 - val_accuracy: 0.6872 - val_loss: 1.0056\n",
      "Epoch 494/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:47\u001b[0m 226ms/step - accuracy: 0.8750 - loss: 0.4669\n",
      "Epoch 494: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8750 - loss: 0.4669 - val_accuracy: 0.6871 - val_loss: 1.0061\n",
      "Epoch 495/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.7798 - loss: 0.6037\n",
      "Epoch 495: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 239ms/step - accuracy: 0.7798 - loss: 0.6037 - val_accuracy: 0.6901 - val_loss: 1.0012\n",
      "Epoch 496/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:51\u001b[0m 229ms/step - accuracy: 0.9375 - loss: 0.2717\n",
      "Epoch 496: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.2717 - val_accuracy: 0.6908 - val_loss: 0.9986\n",
      "Epoch 497/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.7788 - loss: 0.6035\n",
      "Epoch 497: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 239ms/step - accuracy: 0.7788 - loss: 0.6035 - val_accuracy: 0.6899 - val_loss: 0.9954\n",
      "Epoch 498/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:48\u001b[0m 227ms/step - accuracy: 0.7500 - loss: 0.4802\n",
      "Epoch 498: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.4802 - val_accuracy: 0.6911 - val_loss: 0.9944\n",
      "Epoch 499/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.7762 - loss: 0.6023\n",
      "Epoch 499: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 238ms/step - accuracy: 0.7762 - loss: 0.6023 - val_accuracy: 0.6847 - val_loss: 1.0270\n",
      "Epoch 500/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:53\u001b[0m 230ms/step - accuracy: 0.7500 - loss: 0.6272\n",
      "Epoch 500: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.6272 - val_accuracy: 0.6847 - val_loss: 1.0270\n",
      "Epoch 501/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.7718 - loss: 0.6196\n",
      "Epoch 501: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 239ms/step - accuracy: 0.7718 - loss: 0.6196 - val_accuracy: 0.6956 - val_loss: 0.9864\n",
      "Epoch 502/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:31\u001b[0m 217ms/step - accuracy: 0.8750 - loss: 0.4224\n",
      "Epoch 502: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8750 - loss: 0.4224 - val_accuracy: 0.6959 - val_loss: 0.9871\n",
      "Epoch 503/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.7811 - loss: 0.6087\n",
      "Epoch 503: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 239ms/step - accuracy: 0.7811 - loss: 0.6087 - val_accuracy: 0.6919 - val_loss: 0.9927\n",
      "Epoch 504/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:47\u001b[0m 227ms/step - accuracy: 0.6250 - loss: 0.7578\n",
      "Epoch 504: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6250 - loss: 0.7578 - val_accuracy: 0.6922 - val_loss: 0.9942\n",
      "Epoch 505/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.7788 - loss: 0.5991\n",
      "Epoch 505: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 239ms/step - accuracy: 0.7788 - loss: 0.5991 - val_accuracy: 0.6895 - val_loss: 0.9909\n",
      "Epoch 506/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:45\u001b[0m 226ms/step - accuracy: 0.7500 - loss: 0.6194\n",
      "Epoch 506: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.6194 - val_accuracy: 0.6895 - val_loss: 0.9890\n",
      "Epoch 507/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.7752 - loss: 0.6064\n",
      "Epoch 507: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 239ms/step - accuracy: 0.7752 - loss: 0.6064 - val_accuracy: 0.6891 - val_loss: 1.0132\n",
      "Epoch 508/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:52\u001b[0m 229ms/step - accuracy: 0.6875 - loss: 0.7431\n",
      "Epoch 508: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.7431 - val_accuracy: 0.6899 - val_loss: 1.0144\n",
      "Epoch 509/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.7752 - loss: 0.6056\n",
      "Epoch 509: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 239ms/step - accuracy: 0.7752 - loss: 0.6056 - val_accuracy: 0.6680 - val_loss: 1.0473\n",
      "Epoch 510/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:39\u001b[0m 222ms/step - accuracy: 0.6875 - loss: 0.6592\n",
      "Epoch 510: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.6592 - val_accuracy: 0.6686 - val_loss: 1.0437\n",
      "Epoch 511/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.7742 - loss: 0.6103\n",
      "Epoch 511: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 240ms/step - accuracy: 0.7742 - loss: 0.6103 - val_accuracy: 0.6936 - val_loss: 1.0134\n",
      "Epoch 512/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:32\u001b[0m 218ms/step - accuracy: 0.7500 - loss: 0.6249\n",
      "Epoch 512: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.6249 - val_accuracy: 0.6935 - val_loss: 1.0134\n",
      "Epoch 513/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.7810 - loss: 0.5971\n",
      "Epoch 513: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 240ms/step - accuracy: 0.7810 - loss: 0.5971 - val_accuracy: 0.6726 - val_loss: 1.0339\n",
      "Epoch 514/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:37\u001b[0m 221ms/step - accuracy: 0.8125 - loss: 0.6828\n",
      "Epoch 514: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.6828 - val_accuracy: 0.6739 - val_loss: 1.0305\n",
      "Epoch 515/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.7792 - loss: 0.5951\n",
      "Epoch 515: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 240ms/step - accuracy: 0.7792 - loss: 0.5951 - val_accuracy: 0.6646 - val_loss: 1.0889\n",
      "Epoch 516/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:42\u001b[0m 223ms/step - accuracy: 0.9375 - loss: 0.3718\n",
      "Epoch 516: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.3718 - val_accuracy: 0.6618 - val_loss: 1.0985\n",
      "Epoch 517/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.7863 - loss: 0.5805\n",
      "Epoch 517: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 240ms/step - accuracy: 0.7863 - loss: 0.5805 - val_accuracy: 0.6780 - val_loss: 1.0286\n",
      "Epoch 518/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:46\u001b[0m 226ms/step - accuracy: 0.7500 - loss: 0.5834\n",
      "Epoch 518: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.5834 - val_accuracy: 0.6781 - val_loss: 1.0296\n",
      "Epoch 519/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.7815 - loss: 0.5835\n",
      "Epoch 519: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 241ms/step - accuracy: 0.7815 - loss: 0.5835 - val_accuracy: 0.6761 - val_loss: 1.0263\n",
      "Epoch 520/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:27\u001b[0m 248ms/step - accuracy: 0.9375 - loss: 0.3169\n",
      "Epoch 520: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.3169 - val_accuracy: 0.6767 - val_loss: 1.0252\n",
      "Epoch 521/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.7803 - loss: 0.6019\n",
      "Epoch 521: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 274ms/step - accuracy: 0.7803 - loss: 0.6019 - val_accuracy: 0.6881 - val_loss: 0.9786\n",
      "Epoch 522/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:08\u001b[0m 238ms/step - accuracy: 0.7500 - loss: 0.6065\n",
      "Epoch 522: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.6065 - val_accuracy: 0.6879 - val_loss: 0.9783\n",
      "Epoch 523/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.7817 - loss: 0.5849\n",
      "Epoch 523: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 246ms/step - accuracy: 0.7817 - loss: 0.5849 - val_accuracy: 0.6832 - val_loss: 1.0209\n",
      "Epoch 524/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:51\u001b[0m 228ms/step - accuracy: 0.8750 - loss: 0.4086\n",
      "Epoch 524: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8750 - loss: 0.4086 - val_accuracy: 0.6834 - val_loss: 1.0227\n",
      "Epoch 525/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.7879 - loss: 0.5758\n",
      "Epoch 525: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 242ms/step - accuracy: 0.7879 - loss: 0.5758 - val_accuracy: 0.6818 - val_loss: 1.0755\n",
      "Epoch 526/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:04\u001b[0m 236ms/step - accuracy: 0.8750 - loss: 0.3479\n",
      "Epoch 526: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8750 - loss: 0.3479 - val_accuracy: 0.6825 - val_loss: 1.0742\n",
      "Epoch 527/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.7793 - loss: 0.5949\n",
      "Epoch 527: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 242ms/step - accuracy: 0.7793 - loss: 0.5949 - val_accuracy: 0.6842 - val_loss: 0.9988\n",
      "Epoch 528/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m6:42\u001b[0m 224ms/step - accuracy: 0.7500 - loss: 0.5329\n",
      "Epoch 528: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.5329 - val_accuracy: 0.6842 - val_loss: 0.9997\n",
      "Epoch 529/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.7814 - loss: 0.5988\n",
      "Epoch 529: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 255ms/step - accuracy: 0.7814 - loss: 0.5988 - val_accuracy: 0.6646 - val_loss: 1.1087\n",
      "Epoch 530/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:40\u001b[0m 256ms/step - accuracy: 0.8750 - loss: 0.2795\n",
      "Epoch 530: val_accuracy did not improve from 0.69787\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8750 - loss: 0.2795 - val_accuracy: 0.6649 - val_loss: 1.1091\n",
      "Epoch 531/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.7843 - loss: 0.5852\n",
      "Epoch 531: val_accuracy improved from 0.69787 to 0.69957, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 271ms/step - accuracy: 0.7843 - loss: 0.5853 - val_accuracy: 0.6996 - val_loss: 0.9778\n",
      "Epoch 532/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:17\u001b[0m 243ms/step - accuracy: 0.8125 - loss: 0.4083\n",
      "Epoch 532: val_accuracy improved from 0.69957 to 0.69986, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.4083 - val_accuracy: 0.6999 - val_loss: 0.9782\n",
      "Epoch 533/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.7821 - loss: 0.5921\n",
      "Epoch 533: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 271ms/step - accuracy: 0.7821 - loss: 0.5921 - val_accuracy: 0.6892 - val_loss: 1.0019\n",
      "Epoch 534/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:39\u001b[0m 255ms/step - accuracy: 0.6875 - loss: 0.7493\n",
      "Epoch 534: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.7493 - val_accuracy: 0.6888 - val_loss: 1.0004\n",
      "Epoch 535/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.7855 - loss: 0.5798\n",
      "Epoch 535: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 272ms/step - accuracy: 0.7855 - loss: 0.5798 - val_accuracy: 0.6962 - val_loss: 0.9987\n",
      "Epoch 536/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:27\u001b[0m 248ms/step - accuracy: 0.9375 - loss: 0.3272\n",
      "Epoch 536: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.3272 - val_accuracy: 0.6957 - val_loss: 0.9979\n",
      "Epoch 537/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.7794 - loss: 0.5973\n",
      "Epoch 537: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 271ms/step - accuracy: 0.7794 - loss: 0.5973 - val_accuracy: 0.6926 - val_loss: 1.0077\n",
      "Epoch 538/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:51\u001b[0m 262ms/step - accuracy: 0.6875 - loss: 0.7419\n",
      "Epoch 538: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.7419 - val_accuracy: 0.6932 - val_loss: 1.0094\n",
      "Epoch 539/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.7840 - loss: 0.5839\n",
      "Epoch 539: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 271ms/step - accuracy: 0.7840 - loss: 0.5839 - val_accuracy: 0.6864 - val_loss: 1.0329\n",
      "Epoch 540/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:13\u001b[0m 241ms/step - accuracy: 0.7500 - loss: 0.5250\n",
      "Epoch 540: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.5250 - val_accuracy: 0.6868 - val_loss: 1.0314\n",
      "Epoch 541/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.7875 - loss: 0.5878\n",
      "Epoch 541: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 273ms/step - accuracy: 0.7875 - loss: 0.5878 - val_accuracy: 0.6932 - val_loss: 0.9940\n",
      "Epoch 542/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:42\u001b[0m 257ms/step - accuracy: 0.8125 - loss: 0.4026\n",
      "Epoch 542: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.4026 - val_accuracy: 0.6923 - val_loss: 0.9964\n",
      "Epoch 543/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.7884 - loss: 0.5840\n",
      "Epoch 543: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m490s\u001b[0m 272ms/step - accuracy: 0.7884 - loss: 0.5840 - val_accuracy: 0.6920 - val_loss: 1.0186\n",
      "Epoch 544/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:54\u001b[0m 263ms/step - accuracy: 0.9375 - loss: 0.3584\n",
      "Epoch 544: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.3584 - val_accuracy: 0.6926 - val_loss: 1.0199\n",
      "Epoch 545/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.7914 - loss: 0.5739\n",
      "Epoch 545: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 280ms/step - accuracy: 0.7914 - loss: 0.5739 - val_accuracy: 0.6645 - val_loss: 1.0950\n",
      "Epoch 546/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:45\u001b[0m 258ms/step - accuracy: 1.0000 - loss: 0.1593\n",
      "Epoch 546: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.1593 - val_accuracy: 0.6646 - val_loss: 1.0971\n",
      "Epoch 547/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.7872 - loss: 0.5781\n",
      "Epoch 547: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 282ms/step - accuracy: 0.7872 - loss: 0.5781 - val_accuracy: 0.6866 - val_loss: 1.0076\n",
      "Epoch 548/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:26\u001b[0m 248ms/step - accuracy: 0.9375 - loss: 0.3247\n",
      "Epoch 548: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.3247 - val_accuracy: 0.6878 - val_loss: 1.0084\n",
      "Epoch 549/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.7869 - loss: 0.5851\n",
      "Epoch 549: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m498s\u001b[0m 277ms/step - accuracy: 0.7869 - loss: 0.5851 - val_accuracy: 0.6949 - val_loss: 1.0153\n",
      "Epoch 550/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:48\u001b[0m 260ms/step - accuracy: 0.7500 - loss: 0.6869\n",
      "Epoch 550: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.6869 - val_accuracy: 0.6953 - val_loss: 1.0158\n",
      "Epoch 551/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.7851 - loss: 0.5819\n",
      "Epoch 551: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 271ms/step - accuracy: 0.7851 - loss: 0.5819 - val_accuracy: 0.6830 - val_loss: 1.0466\n",
      "Epoch 552/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:25\u001b[0m 248ms/step - accuracy: 0.6250 - loss: 0.8331\n",
      "Epoch 552: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6250 - loss: 0.8331 - val_accuracy: 0.6822 - val_loss: 1.0458\n",
      "Epoch 553/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.7940 - loss: 0.5703\n",
      "Epoch 553: val_accuracy did not improve from 0.69986\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 270ms/step - accuracy: 0.7940 - loss: 0.5703 - val_accuracy: 0.6989 - val_loss: 1.0018\n",
      "Epoch 554/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:13\u001b[0m 274ms/step - accuracy: 0.6875 - loss: 0.7889\n",
      "Epoch 554: val_accuracy improved from 0.69986 to 0.70099, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.7889 - val_accuracy: 0.7010 - val_loss: 1.0001\n",
      "Epoch 555/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.7873 - loss: 0.5727\n",
      "Epoch 555: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 277ms/step - accuracy: 0.7873 - loss: 0.5727 - val_accuracy: 0.6818 - val_loss: 1.0649\n",
      "Epoch 556/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:50\u001b[0m 261ms/step - accuracy: 0.7500 - loss: 0.7012\n",
      "Epoch 556: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.7012 - val_accuracy: 0.6798 - val_loss: 1.0716\n",
      "Epoch 557/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.7840 - loss: 0.5765\n",
      "Epoch 557: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 272ms/step - accuracy: 0.7840 - loss: 0.5765 - val_accuracy: 0.6871 - val_loss: 1.0294\n",
      "Epoch 558/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:39\u001b[0m 255ms/step - accuracy: 0.8750 - loss: 0.3483\n",
      "Epoch 558: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8750 - loss: 0.3483 - val_accuracy: 0.6871 - val_loss: 1.0326\n",
      "Epoch 559/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.7893 - loss: 0.5713\n",
      "Epoch 559: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 270ms/step - accuracy: 0.7893 - loss: 0.5713 - val_accuracy: 0.6808 - val_loss: 1.0478\n",
      "Epoch 560/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:42\u001b[0m 257ms/step - accuracy: 0.8125 - loss: 0.3589\n",
      "Epoch 560: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.3589 - val_accuracy: 0.6814 - val_loss: 1.0417\n",
      "Epoch 561/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.7918 - loss: 0.5659\n",
      "Epoch 561: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 272ms/step - accuracy: 0.7918 - loss: 0.5659 - val_accuracy: 0.6771 - val_loss: 1.0661\n",
      "Epoch 562/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:14\u001b[0m 275ms/step - accuracy: 0.8125 - loss: 0.5045\n",
      "Epoch 562: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.5045 - val_accuracy: 0.6784 - val_loss: 1.0561\n",
      "Epoch 563/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.7932 - loss: 0.5685\n",
      "Epoch 563: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 272ms/step - accuracy: 0.7932 - loss: 0.5685 - val_accuracy: 0.6687 - val_loss: 1.0654\n",
      "Epoch 564/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:10\u001b[0m 273ms/step - accuracy: 0.8125 - loss: 0.4003\n",
      "Epoch 564: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.4003 - val_accuracy: 0.6702 - val_loss: 1.0621\n",
      "Epoch 565/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.7923 - loss: 0.5732\n",
      "Epoch 565: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 275ms/step - accuracy: 0.7923 - loss: 0.5732 - val_accuracy: 0.6810 - val_loss: 1.0452\n",
      "Epoch 566/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:52\u001b[0m 262ms/step - accuracy: 0.8125 - loss: 0.6257\n",
      "Epoch 566: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.6257 - val_accuracy: 0.6795 - val_loss: 1.0464\n",
      "Epoch 567/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.7948 - loss: 0.5624\n",
      "Epoch 567: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m512s\u001b[0m 284ms/step - accuracy: 0.7948 - loss: 0.5624 - val_accuracy: 0.6855 - val_loss: 1.0425\n",
      "Epoch 568/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:01\u001b[0m 267ms/step - accuracy: 0.7500 - loss: 0.4946\n",
      "Epoch 568: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.7500 - loss: 0.4946 - val_accuracy: 0.6845 - val_loss: 1.0447\n",
      "Epoch 569/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.7880 - loss: 0.5756\n",
      "Epoch 569: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 285ms/step - accuracy: 0.7880 - loss: 0.5756 - val_accuracy: 0.6966 - val_loss: 1.0353\n",
      "Epoch 570/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:50\u001b[0m 261ms/step - accuracy: 0.6250 - loss: 1.0648\n",
      "Epoch 570: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6250 - loss: 1.0648 - val_accuracy: 0.6977 - val_loss: 1.0326\n",
      "Epoch 571/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.7946 - loss: 0.5599\n",
      "Epoch 571: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 285ms/step - accuracy: 0.7946 - loss: 0.5599 - val_accuracy: 0.6940 - val_loss: 1.0362\n",
      "Epoch 572/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:44\u001b[0m 258ms/step - accuracy: 0.6875 - loss: 0.6614\n",
      "Epoch 572: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.6614 - val_accuracy: 0.6943 - val_loss: 1.0363\n",
      "Epoch 573/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.7907 - loss: 0.5714\n",
      "Epoch 573: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 285ms/step - accuracy: 0.7907 - loss: 0.5714 - val_accuracy: 0.6706 - val_loss: 1.1086\n",
      "Epoch 574/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:59\u001b[0m 267ms/step - accuracy: 0.6250 - loss: 0.6129\n",
      "Epoch 574: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.6250 - loss: 0.6129 - val_accuracy: 0.6693 - val_loss: 1.1129\n",
      "Epoch 575/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.7928 - loss: 0.5681\n",
      "Epoch 575: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 286ms/step - accuracy: 0.7928 - loss: 0.5681 - val_accuracy: 0.6520 - val_loss: 1.1604\n",
      "Epoch 576/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:06\u001b[0m 270ms/step - accuracy: 0.6875 - loss: 0.6564\n",
      "Epoch 576: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.6875 - loss: 0.6564 - val_accuracy: 0.6506 - val_loss: 1.1622\n",
      "Epoch 577/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.7869 - loss: 0.5664\n",
      "Epoch 577: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 285ms/step - accuracy: 0.7870 - loss: 0.5664 - val_accuracy: 0.6653 - val_loss: 1.1114\n",
      "Epoch 578/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:43\u001b[0m 291ms/step - accuracy: 0.7500 - loss: 0.8288\n",
      "Epoch 578: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.7500 - loss: 0.8288 - val_accuracy: 0.6599 - val_loss: 1.1227\n",
      "Epoch 579/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.7898 - loss: 0.5657\n",
      "Epoch 579: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 285ms/step - accuracy: 0.7898 - loss: 0.5657 - val_accuracy: 0.6608 - val_loss: 1.1488\n",
      "Epoch 580/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:44\u001b[0m 258ms/step - accuracy: 0.7500 - loss: 0.5165\n",
      "Epoch 580: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.7500 - loss: 0.5165 - val_accuracy: 0.6631 - val_loss: 1.1435\n",
      "Epoch 581/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.7930 - loss: 0.5577\n",
      "Epoch 581: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 286ms/step - accuracy: 0.7930 - loss: 0.5577 - val_accuracy: 0.6810 - val_loss: 1.0505\n",
      "Epoch 582/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:54\u001b[0m 264ms/step - accuracy: 0.8125 - loss: 0.6271\n",
      "Epoch 582: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8125 - loss: 0.6271 - val_accuracy: 0.6787 - val_loss: 1.0539\n",
      "Epoch 583/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.7935 - loss: 0.5569\n",
      "Epoch 583: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 286ms/step - accuracy: 0.7935 - loss: 0.5569 - val_accuracy: 0.6793 - val_loss: 1.0838\n",
      "Epoch 584/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:30\u001b[0m 250ms/step - accuracy: 0.6875 - loss: 0.4780\n",
      "Epoch 584: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.6875 - loss: 0.4780 - val_accuracy: 0.6803 - val_loss: 1.0825\n",
      "Epoch 585/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.7925 - loss: 0.5640\n",
      "Epoch 585: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 286ms/step - accuracy: 0.7925 - loss: 0.5640 - val_accuracy: 0.6920 - val_loss: 1.0130\n",
      "Epoch 586/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:54\u001b[0m 264ms/step - accuracy: 0.8750 - loss: 0.4812\n",
      "Epoch 586: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.4812 - val_accuracy: 0.6908 - val_loss: 1.0148\n",
      "Epoch 587/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.7948 - loss: 0.5600\n",
      "Epoch 587: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 286ms/step - accuracy: 0.7948 - loss: 0.5600 - val_accuracy: 0.6669 - val_loss: 1.1102\n",
      "Epoch 588/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m9:03\u001b[0m 302ms/step - accuracy: 0.8125 - loss: 0.3348\n",
      "Epoch 588: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8125 - loss: 0.3348 - val_accuracy: 0.6683 - val_loss: 1.1033\n",
      "Epoch 589/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.7944 - loss: 0.5640\n",
      "Epoch 589: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m519s\u001b[0m 288ms/step - accuracy: 0.7944 - loss: 0.5640 - val_accuracy: 0.6773 - val_loss: 1.0822\n",
      "Epoch 590/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:00\u001b[0m 267ms/step - accuracy: 0.8750 - loss: 0.4567\n",
      "Epoch 590: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.4567 - val_accuracy: 0.6736 - val_loss: 1.0913\n",
      "Epoch 591/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.7936 - loss: 0.5535\n",
      "Epoch 591: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 281ms/step - accuracy: 0.7936 - loss: 0.5535 - val_accuracy: 0.6905 - val_loss: 1.0528\n",
      "Epoch 592/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:38\u001b[0m 255ms/step - accuracy: 0.6875 - loss: 0.7324\n",
      "Epoch 592: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.7324 - val_accuracy: 0.6896 - val_loss: 1.0538\n",
      "Epoch 593/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.7937 - loss: 0.5624\n",
      "Epoch 593: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 279ms/step - accuracy: 0.7937 - loss: 0.5624 - val_accuracy: 0.6787 - val_loss: 1.0647\n",
      "Epoch 594/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:35\u001b[0m 253ms/step - accuracy: 0.6250 - loss: 1.4317\n",
      "Epoch 594: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6250 - loss: 1.4317 - val_accuracy: 0.6798 - val_loss: 1.0603\n",
      "Epoch 595/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.7947 - loss: 0.5645\n",
      "Epoch 595: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 280ms/step - accuracy: 0.7947 - loss: 0.5645 - val_accuracy: 0.6908 - val_loss: 1.0461\n",
      "Epoch 596/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:31\u001b[0m 251ms/step - accuracy: 0.8750 - loss: 0.4498\n",
      "Epoch 596: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8750 - loss: 0.4498 - val_accuracy: 0.6909 - val_loss: 1.0476\n",
      "Epoch 597/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.7924 - loss: 0.5665\n",
      "Epoch 597: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 280ms/step - accuracy: 0.7924 - loss: 0.5665 - val_accuracy: 0.6960 - val_loss: 1.0307\n",
      "Epoch 598/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:59\u001b[0m 267ms/step - accuracy: 0.8750 - loss: 0.3649\n",
      "Epoch 598: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8750 - loss: 0.3649 - val_accuracy: 0.6953 - val_loss: 1.0349\n",
      "Epoch 599/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.7930 - loss: 0.5579\n",
      "Epoch 599: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 281ms/step - accuracy: 0.7930 - loss: 0.5579 - val_accuracy: 0.6854 - val_loss: 1.0440\n",
      "Epoch 600/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:54\u001b[0m 263ms/step - accuracy: 0.5625 - loss: 0.9467\n",
      "Epoch 600: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.5625 - loss: 0.9467 - val_accuracy: 0.6858 - val_loss: 1.0435\n",
      "Epoch 601/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.7954 - loss: 0.5572\n",
      "Epoch 601: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 280ms/step - accuracy: 0.7954 - loss: 0.5572 - val_accuracy: 0.6908 - val_loss: 1.0492\n",
      "Epoch 602/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:37\u001b[0m 254ms/step - accuracy: 0.9375 - loss: 0.3415\n",
      "Epoch 602: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.3415 - val_accuracy: 0.6920 - val_loss: 1.0506\n",
      "Epoch 603/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.7962 - loss: 0.5606\n",
      "Epoch 603: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 281ms/step - accuracy: 0.7962 - loss: 0.5606 - val_accuracy: 0.6957 - val_loss: 1.0340\n",
      "Epoch 604/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:58\u001b[0m 266ms/step - accuracy: 0.7500 - loss: 0.4246\n",
      "Epoch 604: val_accuracy did not improve from 0.70099\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.4246 - val_accuracy: 0.6955 - val_loss: 1.0343\n",
      "Epoch 605/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.7956 - loss: 0.5538\n",
      "Epoch 605: val_accuracy improved from 0.70099 to 0.70114, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 282ms/step - accuracy: 0.7956 - loss: 0.5538 - val_accuracy: 0.7011 - val_loss: 1.0133\n",
      "Epoch 606/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:33\u001b[0m 252ms/step - accuracy: 0.7500 - loss: 0.7065\n",
      "Epoch 606: val_accuracy improved from 0.70114 to 0.70128, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.7065 - val_accuracy: 0.7013 - val_loss: 1.0130\n",
      "Epoch 607/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.7995 - loss: 0.5521\n",
      "Epoch 607: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 282ms/step - accuracy: 0.7995 - loss: 0.5521 - val_accuracy: 0.6956 - val_loss: 1.0300\n",
      "Epoch 608/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:40\u001b[0m 289ms/step - accuracy: 0.6875 - loss: 0.7296\n",
      "Epoch 608: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6875 - loss: 0.7296 - val_accuracy: 0.6960 - val_loss: 1.0291\n",
      "Epoch 609/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.7992 - loss: 0.5516\n",
      "Epoch 609: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 278ms/step - accuracy: 0.7992 - loss: 0.5516 - val_accuracy: 0.6945 - val_loss: 1.0349\n",
      "Epoch 610/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:01\u001b[0m 267ms/step - accuracy: 0.7500 - loss: 0.7893\n",
      "Epoch 610: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.7893 - val_accuracy: 0.6940 - val_loss: 1.0363\n",
      "Epoch 611/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.7948 - loss: 0.5596\n",
      "Epoch 611: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 283ms/step - accuracy: 0.7948 - loss: 0.5596 - val_accuracy: 0.6841 - val_loss: 1.0685\n",
      "Epoch 612/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:16\u001b[0m 276ms/step - accuracy: 0.7500 - loss: 0.5511\n",
      "Epoch 612: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.5511 - val_accuracy: 0.6854 - val_loss: 1.0639\n",
      "Epoch 613/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.8017 - loss: 0.5485\n",
      "Epoch 613: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 282ms/step - accuracy: 0.8017 - loss: 0.5485 - val_accuracy: 0.6916 - val_loss: 1.0348\n",
      "Epoch 614/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:10\u001b[0m 272ms/step - accuracy: 0.8750 - loss: 0.3394\n",
      "Epoch 614: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8750 - loss: 0.3394 - val_accuracy: 0.6922 - val_loss: 1.0385\n",
      "Epoch 615/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.8006 - loss: 0.5432\n",
      "Epoch 615: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m510s\u001b[0m 283ms/step - accuracy: 0.8006 - loss: 0.5432 - val_accuracy: 0.6938 - val_loss: 1.0570\n",
      "Epoch 616/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:55\u001b[0m 264ms/step - accuracy: 0.6250 - loss: 0.7252\n",
      "Epoch 616: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6250 - loss: 0.7252 - val_accuracy: 0.6945 - val_loss: 1.0563\n",
      "Epoch 617/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.8030 - loss: 0.5403\n",
      "Epoch 617: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 304ms/step - accuracy: 0.8030 - loss: 0.5403 - val_accuracy: 0.6901 - val_loss: 1.0681\n",
      "Epoch 618/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:18\u001b[0m 277ms/step - accuracy: 0.8125 - loss: 0.4236\n",
      "Epoch 618: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.4236 - val_accuracy: 0.6902 - val_loss: 1.0691\n",
      "Epoch 619/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.8014 - loss: 0.5405\n",
      "Epoch 619: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m526s\u001b[0m 292ms/step - accuracy: 0.8014 - loss: 0.5405 - val_accuracy: 0.6997 - val_loss: 1.0310\n",
      "Epoch 620/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:59\u001b[0m 266ms/step - accuracy: 0.9375 - loss: 0.3426\n",
      "Epoch 620: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.3426 - val_accuracy: 0.6993 - val_loss: 1.0305\n",
      "Epoch 621/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.7999 - loss: 0.5447\n",
      "Epoch 621: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 285ms/step - accuracy: 0.7999 - loss: 0.5447 - val_accuracy: 0.6359 - val_loss: 1.2407\n",
      "Epoch 622/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:03\u001b[0m 269ms/step - accuracy: 0.8125 - loss: 0.4953\n",
      "Epoch 622: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.4953 - val_accuracy: 0.6393 - val_loss: 1.2326\n",
      "Epoch 623/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.7994 - loss: 0.5392\n",
      "Epoch 623: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 289ms/step - accuracy: 0.7994 - loss: 0.5392 - val_accuracy: 0.6930 - val_loss: 1.0449\n",
      "Epoch 624/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:33\u001b[0m 285ms/step - accuracy: 0.6250 - loss: 0.7972\n",
      "Epoch 624: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6250 - loss: 0.7972 - val_accuracy: 0.6929 - val_loss: 1.0435\n",
      "Epoch 625/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.8021 - loss: 0.5445\n",
      "Epoch 625: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m521s\u001b[0m 289ms/step - accuracy: 0.8021 - loss: 0.5445 - val_accuracy: 0.6946 - val_loss: 1.0511\n",
      "Epoch 626/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:40\u001b[0m 289ms/step - accuracy: 0.6875 - loss: 0.6064\n",
      "Epoch 626: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.6875 - loss: 0.6064 - val_accuracy: 0.6952 - val_loss: 1.0542\n",
      "Epoch 627/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.8029 - loss: 0.5373\n",
      "Epoch 627: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m521s\u001b[0m 289ms/step - accuracy: 0.8029 - loss: 0.5373 - val_accuracy: 0.6713 - val_loss: 1.1306\n",
      "Epoch 628/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:02\u001b[0m 268ms/step - accuracy: 0.8750 - loss: 0.2493\n",
      "Epoch 628: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.2493 - val_accuracy: 0.6702 - val_loss: 1.1389\n",
      "Epoch 629/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.7978 - loss: 0.5570\n",
      "Epoch 629: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m523s\u001b[0m 291ms/step - accuracy: 0.7978 - loss: 0.5570 - val_accuracy: 0.6727 - val_loss: 1.1184\n",
      "Epoch 630/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m9:17\u001b[0m 310ms/step - accuracy: 0.8750 - loss: 0.2798\n",
      "Epoch 630: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.2798 - val_accuracy: 0.6713 - val_loss: 1.1214\n",
      "Epoch 631/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.8032 - loss: 0.5380\n",
      "Epoch 631: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m523s\u001b[0m 291ms/step - accuracy: 0.8032 - loss: 0.5380 - val_accuracy: 0.6406 - val_loss: 1.2051\n",
      "Epoch 632/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:15\u001b[0m 275ms/step - accuracy: 0.6250 - loss: 1.1966\n",
      "Epoch 632: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.6250 - loss: 1.1966 - val_accuracy: 0.6418 - val_loss: 1.2011\n",
      "Epoch 633/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.8010 - loss: 0.5377\n",
      "Epoch 633: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m523s\u001b[0m 290ms/step - accuracy: 0.8010 - loss: 0.5377 - val_accuracy: 0.6851 - val_loss: 1.1070\n",
      "Epoch 634/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:31\u001b[0m 284ms/step - accuracy: 0.7500 - loss: 0.4386\n",
      "Epoch 634: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.7500 - loss: 0.4386 - val_accuracy: 0.6848 - val_loss: 1.1061\n",
      "Epoch 635/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.8014 - loss: 0.5414\n",
      "Epoch 635: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m525s\u001b[0m 291ms/step - accuracy: 0.8014 - loss: 0.5414 - val_accuracy: 0.6811 - val_loss: 1.0677\n",
      "Epoch 636/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:14\u001b[0m 275ms/step - accuracy: 0.9375 - loss: 0.2031\n",
      "Epoch 636: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.9375 - loss: 0.2031 - val_accuracy: 0.6842 - val_loss: 1.0628\n",
      "Epoch 637/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.7964 - loss: 0.5523\n",
      "Epoch 637: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 274ms/step - accuracy: 0.7964 - loss: 0.5523 - val_accuracy: 0.6777 - val_loss: 1.1045\n",
      "Epoch 638/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:49\u001b[0m 261ms/step - accuracy: 0.8750 - loss: 0.4750\n",
      "Epoch 638: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8750 - loss: 0.4750 - val_accuracy: 0.6766 - val_loss: 1.1057\n",
      "Epoch 639/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.8009 - loss: 0.5436\n",
      "Epoch 639: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m486s\u001b[0m 270ms/step - accuracy: 0.8009 - loss: 0.5436 - val_accuracy: 0.6839 - val_loss: 1.0607\n",
      "Epoch 640/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:11\u001b[0m 273ms/step - accuracy: 0.8125 - loss: 0.5269\n",
      "Epoch 640: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.5269 - val_accuracy: 0.6851 - val_loss: 1.0583\n",
      "Epoch 641/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.8063 - loss: 0.5370\n",
      "Epoch 641: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 270ms/step - accuracy: 0.8063 - loss: 0.5370 - val_accuracy: 0.6911 - val_loss: 1.0419\n",
      "Epoch 642/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:42\u001b[0m 257ms/step - accuracy: 0.7500 - loss: 0.9981\n",
      "Epoch 642: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.9981 - val_accuracy: 0.6906 - val_loss: 1.0425\n",
      "Epoch 643/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.8003 - loss: 0.5400\n",
      "Epoch 643: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 273ms/step - accuracy: 0.8003 - loss: 0.5400 - val_accuracy: 0.6710 - val_loss: 1.1119\n",
      "Epoch 644/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:10\u001b[0m 272ms/step - accuracy: 0.6250 - loss: 1.0069\n",
      "Epoch 644: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6250 - loss: 1.0069 - val_accuracy: 0.6720 - val_loss: 1.1090\n",
      "Epoch 645/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.8023 - loss: 0.5350\n",
      "Epoch 645: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 272ms/step - accuracy: 0.8023 - loss: 0.5350 - val_accuracy: 0.6922 - val_loss: 1.0498\n",
      "Epoch 646/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:13\u001b[0m 241ms/step - accuracy: 0.5625 - loss: 0.9610\n",
      "Epoch 646: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.5625 - loss: 0.9610 - val_accuracy: 0.6919 - val_loss: 1.0511\n",
      "Epoch 647/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.8089 - loss: 0.5316\n",
      "Epoch 647: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m490s\u001b[0m 272ms/step - accuracy: 0.8089 - loss: 0.5316 - val_accuracy: 0.6798 - val_loss: 1.0771\n",
      "Epoch 648/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:56\u001b[0m 265ms/step - accuracy: 0.9375 - loss: 0.2243\n",
      "Epoch 648: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.2243 - val_accuracy: 0.6784 - val_loss: 1.0808\n",
      "Epoch 649/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.8078 - loss: 0.5339\n",
      "Epoch 649: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 287ms/step - accuracy: 0.8078 - loss: 0.5339 - val_accuracy: 0.6865 - val_loss: 1.0724\n",
      "Epoch 650/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:56\u001b[0m 265ms/step - accuracy: 0.8750 - loss: 0.2976\n",
      "Epoch 650: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.2976 - val_accuracy: 0.6872 - val_loss: 1.0705\n",
      "Epoch 651/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.8080 - loss: 0.5232\n",
      "Epoch 651: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m522s\u001b[0m 290ms/step - accuracy: 0.8080 - loss: 0.5232 - val_accuracy: 0.6837 - val_loss: 1.0688\n",
      "Epoch 652/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:02\u001b[0m 268ms/step - accuracy: 0.8125 - loss: 0.4057\n",
      "Epoch 652: val_accuracy did not improve from 0.70128\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8125 - loss: 0.4057 - val_accuracy: 0.6847 - val_loss: 1.0676\n",
      "Epoch 653/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.8056 - loss: 0.5280\n",
      "Epoch 653: val_accuracy improved from 0.70128 to 0.70227, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 294ms/step - accuracy: 0.8056 - loss: 0.5280 - val_accuracy: 0.7023 - val_loss: 1.0195\n",
      "Epoch 654/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:05\u001b[0m 270ms/step - accuracy: 0.8125 - loss: 0.4245\n",
      "Epoch 654: val_accuracy improved from 0.70227 to 0.70284, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8125 - loss: 0.4245 - val_accuracy: 0.7028 - val_loss: 1.0189\n",
      "Epoch 655/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.8060 - loss: 0.5277\n",
      "Epoch 655: val_accuracy did not improve from 0.70284\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 291ms/step - accuracy: 0.8060 - loss: 0.5277 - val_accuracy: 0.6875 - val_loss: 1.0771\n",
      "Epoch 656/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:26\u001b[0m 281ms/step - accuracy: 0.8125 - loss: 0.3672\n",
      "Epoch 656: val_accuracy did not improve from 0.70284\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8125 - loss: 0.3672 - val_accuracy: 0.6862 - val_loss: 1.0817\n",
      "Epoch 657/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.8061 - loss: 0.5261\n",
      "Epoch 657: val_accuracy did not improve from 0.70284\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m531s\u001b[0m 295ms/step - accuracy: 0.8061 - loss: 0.5261 - val_accuracy: 0.6714 - val_loss: 1.1521\n",
      "Epoch 658/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:16\u001b[0m 276ms/step - accuracy: 0.7500 - loss: 0.5327\n",
      "Epoch 658: val_accuracy did not improve from 0.70284\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7500 - loss: 0.5327 - val_accuracy: 0.6730 - val_loss: 1.1458\n",
      "Epoch 659/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.8064 - loss: 0.5381\n",
      "Epoch 659: val_accuracy did not improve from 0.70284\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 294ms/step - accuracy: 0.8064 - loss: 0.5381 - val_accuracy: 0.6835 - val_loss: 1.0772\n",
      "Epoch 660/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:55\u001b[0m 264ms/step - accuracy: 0.6875 - loss: 0.8566\n",
      "Epoch 660: val_accuracy did not improve from 0.70284\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6875 - loss: 0.8566 - val_accuracy: 0.6839 - val_loss: 1.0763\n",
      "Epoch 661/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.8030 - loss: 0.5331\n",
      "Epoch 661: val_accuracy improved from 0.70284 to 0.70526, saving model to model_weights.keras\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m540s\u001b[0m 300ms/step - accuracy: 0.8030 - loss: 0.5331 - val_accuracy: 0.7053 - val_loss: 1.0302\n",
      "Epoch 662/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:57\u001b[0m 299ms/step - accuracy: 0.6875 - loss: 0.6526\n",
      "Epoch 662: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6875 - loss: 0.6526 - val_accuracy: 0.7045 - val_loss: 1.0289\n",
      "Epoch 663/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.8067 - loss: 0.5295\n",
      "Epoch 663: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 295ms/step - accuracy: 0.8067 - loss: 0.5295 - val_accuracy: 0.6906 - val_loss: 1.0624\n",
      "Epoch 664/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:15\u001b[0m 275ms/step - accuracy: 1.0000 - loss: 0.1669\n",
      "Epoch 664: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.1669 - val_accuracy: 0.6899 - val_loss: 1.0633\n",
      "Epoch 665/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.7985 - loss: 0.5384\n",
      "Epoch 665: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 291ms/step - accuracy: 0.7985 - loss: 0.5384 - val_accuracy: 0.6771 - val_loss: 1.0978\n",
      "Epoch 666/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:05\u001b[0m 270ms/step - accuracy: 0.8750 - loss: 0.4157\n",
      "Epoch 666: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.4157 - val_accuracy: 0.6754 - val_loss: 1.1015\n",
      "Epoch 667/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.8126 - loss: 0.5312\n",
      "Epoch 667: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 293ms/step - accuracy: 0.8126 - loss: 0.5312 - val_accuracy: 0.6830 - val_loss: 1.0841\n",
      "Epoch 668/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:13\u001b[0m 274ms/step - accuracy: 0.8750 - loss: 0.4022\n",
      "Epoch 668: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.4022 - val_accuracy: 0.6838 - val_loss: 1.0825\n",
      "Epoch 669/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.8073 - loss: 0.5202\n",
      "Epoch 669: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m521s\u001b[0m 289ms/step - accuracy: 0.8073 - loss: 0.5202 - val_accuracy: 0.6852 - val_loss: 1.0984\n",
      "Epoch 670/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:49\u001b[0m 261ms/step - accuracy: 0.8125 - loss: 0.5734\n",
      "Epoch 670: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8125 - loss: 0.5734 - val_accuracy: 0.6852 - val_loss: 1.0966\n",
      "Epoch 671/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.8104 - loss: 0.5159\n",
      "Epoch 671: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m529s\u001b[0m 294ms/step - accuracy: 0.8104 - loss: 0.5159 - val_accuracy: 0.6911 - val_loss: 1.0628\n",
      "Epoch 672/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:23\u001b[0m 280ms/step - accuracy: 0.7500 - loss: 0.5206\n",
      "Epoch 672: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.7500 - loss: 0.5206 - val_accuracy: 0.6912 - val_loss: 1.0614\n",
      "Epoch 673/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.8095 - loss: 0.5333\n",
      "Epoch 673: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m525s\u001b[0m 292ms/step - accuracy: 0.8095 - loss: 0.5333 - val_accuracy: 0.6776 - val_loss: 1.1006\n",
      "Epoch 674/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:01\u001b[0m 267ms/step - accuracy: 0.8750 - loss: 0.2425\n",
      "Epoch 674: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.2425 - val_accuracy: 0.6770 - val_loss: 1.1038\n",
      "Epoch 675/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.8043 - loss: 0.5276\n",
      "Epoch 675: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m526s\u001b[0m 292ms/step - accuracy: 0.8043 - loss: 0.5276 - val_accuracy: 0.6935 - val_loss: 1.0456\n",
      "Epoch 676/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:11\u001b[0m 273ms/step - accuracy: 0.6875 - loss: 0.6655\n",
      "Epoch 676: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6875 - loss: 0.6655 - val_accuracy: 0.6919 - val_loss: 1.0483\n",
      "Epoch 677/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.7987 - loss: 0.5433\n",
      "Epoch 677: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m529s\u001b[0m 294ms/step - accuracy: 0.7987 - loss: 0.5433 - val_accuracy: 0.7018 - val_loss: 1.0238\n",
      "Epoch 678/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:05\u001b[0m 270ms/step - accuracy: 0.7500 - loss: 0.6241\n",
      "Epoch 678: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7500 - loss: 0.6241 - val_accuracy: 0.7030 - val_loss: 1.0223\n",
      "Epoch 679/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.8106 - loss: 0.5179\n",
      "Epoch 679: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m522s\u001b[0m 290ms/step - accuracy: 0.8106 - loss: 0.5179 - val_accuracy: 0.6885 - val_loss: 1.0536\n",
      "Epoch 680/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m9:10\u001b[0m 306ms/step - accuracy: 0.8750 - loss: 0.5470\n",
      "Epoch 680: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.5470 - val_accuracy: 0.6881 - val_loss: 1.0563\n",
      "Epoch 681/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.8120 - loss: 0.5164\n",
      "Epoch 681: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 294ms/step - accuracy: 0.8120 - loss: 0.5164 - val_accuracy: 0.6970 - val_loss: 1.0518\n",
      "Epoch 682/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:10\u001b[0m 272ms/step - accuracy: 0.7500 - loss: 0.4601\n",
      "Epoch 682: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.7500 - loss: 0.4601 - val_accuracy: 0.6977 - val_loss: 1.0514\n",
      "Epoch 683/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.8085 - loss: 0.5185\n",
      "Epoch 683: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m526s\u001b[0m 292ms/step - accuracy: 0.8085 - loss: 0.5185 - val_accuracy: 0.6970 - val_loss: 1.0707\n",
      "Epoch 684/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:11\u001b[0m 273ms/step - accuracy: 0.8750 - loss: 0.3019\n",
      "Epoch 684: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.3019 - val_accuracy: 0.6955 - val_loss: 1.0736\n",
      "Epoch 685/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.8060 - loss: 0.5229\n",
      "Epoch 685: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m573s\u001b[0m 318ms/step - accuracy: 0.8060 - loss: 0.5229 - val_accuracy: 0.6986 - val_loss: 1.0661\n",
      "Epoch 686/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:02\u001b[0m 268ms/step - accuracy: 0.5625 - loss: 1.1536\n",
      "Epoch 686: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.5625 - loss: 1.1536 - val_accuracy: 0.6973 - val_loss: 1.0662\n",
      "Epoch 687/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.8123 - loss: 0.5190\n",
      "Epoch 687: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m537s\u001b[0m 298ms/step - accuracy: 0.8123 - loss: 0.5190 - val_accuracy: 0.6920 - val_loss: 1.0709\n",
      "Epoch 688/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:25\u001b[0m 281ms/step - accuracy: 0.8125 - loss: 0.8935\n",
      "Epoch 688: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8125 - loss: 0.8935 - val_accuracy: 0.6923 - val_loss: 1.0669\n",
      "Epoch 689/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.8098 - loss: 0.5231\n",
      "Epoch 689: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m531s\u001b[0m 295ms/step - accuracy: 0.8098 - loss: 0.5231 - val_accuracy: 0.6912 - val_loss: 1.0689\n",
      "Epoch 690/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:28\u001b[0m 282ms/step - accuracy: 0.9375 - loss: 0.2704\n",
      "Epoch 690: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9375 - loss: 0.2704 - val_accuracy: 0.6881 - val_loss: 1.0736\n",
      "Epoch 691/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.8089 - loss: 0.5223\n",
      "Epoch 691: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 294ms/step - accuracy: 0.8089 - loss: 0.5223 - val_accuracy: 0.6956 - val_loss: 1.0514\n",
      "Epoch 692/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:57\u001b[0m 265ms/step - accuracy: 0.9375 - loss: 0.3430\n",
      "Epoch 692: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9375 - loss: 0.3430 - val_accuracy: 0.6962 - val_loss: 1.0537\n",
      "Epoch 693/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.8103 - loss: 0.5215\n",
      "Epoch 693: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 293ms/step - accuracy: 0.8103 - loss: 0.5215 - val_accuracy: 0.6896 - val_loss: 1.0749\n",
      "Epoch 694/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:16\u001b[0m 276ms/step - accuracy: 0.8125 - loss: 0.6772\n",
      "Epoch 694: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8125 - loss: 0.6772 - val_accuracy: 0.6901 - val_loss: 1.0742\n",
      "Epoch 695/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.8136 - loss: 0.5139\n",
      "Epoch 695: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 293ms/step - accuracy: 0.8136 - loss: 0.5139 - val_accuracy: 0.6974 - val_loss: 1.0497\n",
      "Epoch 696/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:02\u001b[0m 268ms/step - accuracy: 0.7500 - loss: 0.5106\n",
      "Epoch 696: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.7500 - loss: 0.5106 - val_accuracy: 0.6977 - val_loss: 1.0493\n",
      "Epoch 697/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.8049 - loss: 0.5230\n",
      "Epoch 697: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m526s\u001b[0m 292ms/step - accuracy: 0.8049 - loss: 0.5230 - val_accuracy: 0.6847 - val_loss: 1.0939\n",
      "Epoch 698/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:03\u001b[0m 269ms/step - accuracy: 0.8750 - loss: 0.6193\n",
      "Epoch 698: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.6193 - val_accuracy: 0.6838 - val_loss: 1.0967\n",
      "Epoch 699/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.8082 - loss: 0.5213\n",
      "Epoch 699: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 295ms/step - accuracy: 0.8082 - loss: 0.5213 - val_accuracy: 0.6509 - val_loss: 1.1827\n",
      "Epoch 700/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:03\u001b[0m 268ms/step - accuracy: 0.8125 - loss: 0.6289\n",
      "Epoch 700: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8125 - loss: 0.6289 - val_accuracy: 0.6483 - val_loss: 1.1945\n",
      "Epoch 701/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.8102 - loss: 0.5098\n",
      "Epoch 701: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 295ms/step - accuracy: 0.8102 - loss: 0.5098 - val_accuracy: 0.6531 - val_loss: 1.2037\n",
      "Epoch 702/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m9:05\u001b[0m 303ms/step - accuracy: 0.6875 - loss: 0.5152\n",
      "Epoch 702: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6875 - loss: 0.5152 - val_accuracy: 0.6509 - val_loss: 1.2188\n",
      "Epoch 703/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.8022 - loss: 0.5278\n",
      "Epoch 703: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m529s\u001b[0m 294ms/step - accuracy: 0.8022 - loss: 0.5278 - val_accuracy: 0.6849 - val_loss: 1.0688\n",
      "Epoch 704/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:09\u001b[0m 272ms/step - accuracy: 0.8125 - loss: 0.4602\n",
      "Epoch 704: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8125 - loss: 0.4602 - val_accuracy: 0.6868 - val_loss: 1.0626\n",
      "Epoch 705/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.8167 - loss: 0.5126\n",
      "Epoch 705: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 294ms/step - accuracy: 0.8167 - loss: 0.5126 - val_accuracy: 0.6790 - val_loss: 1.1328\n",
      "Epoch 706/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:06\u001b[0m 270ms/step - accuracy: 0.7500 - loss: 0.4900\n",
      "Epoch 706: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7500 - loss: 0.4900 - val_accuracy: 0.6781 - val_loss: 1.1343\n",
      "Epoch 707/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.8130 - loss: 0.5089\n",
      "Epoch 707: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m533s\u001b[0m 296ms/step - accuracy: 0.8130 - loss: 0.5089 - val_accuracy: 0.6902 - val_loss: 1.0647\n",
      "Epoch 708/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:54\u001b[0m 297ms/step - accuracy: 0.6875 - loss: 0.6808\n",
      "Epoch 708: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6875 - loss: 0.6808 - val_accuracy: 0.6905 - val_loss: 1.0610\n",
      "Epoch 709/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.8099 - loss: 0.5093\n",
      "Epoch 709: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m531s\u001b[0m 295ms/step - accuracy: 0.8099 - loss: 0.5093 - val_accuracy: 0.6926 - val_loss: 1.0695\n",
      "Epoch 710/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:21\u001b[0m 279ms/step - accuracy: 0.7500 - loss: 0.7588\n",
      "Epoch 710: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7500 - loss: 0.7588 - val_accuracy: 0.6925 - val_loss: 1.0673\n",
      "Epoch 711/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.8065 - loss: 0.5176\n",
      "Epoch 711: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 295ms/step - accuracy: 0.8065 - loss: 0.5176 - val_accuracy: 0.6832 - val_loss: 1.0963\n",
      "Epoch 712/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:12\u001b[0m 274ms/step - accuracy: 0.8125 - loss: 0.3564\n",
      "Epoch 712: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8125 - loss: 0.3564 - val_accuracy: 0.6834 - val_loss: 1.0982\n",
      "Epoch 713/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.8093 - loss: 0.5174\n",
      "Epoch 713: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 294ms/step - accuracy: 0.8093 - loss: 0.5174 - val_accuracy: 0.6915 - val_loss: 1.0433\n",
      "Epoch 714/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:19\u001b[0m 277ms/step - accuracy: 0.7500 - loss: 0.8657\n",
      "Epoch 714: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7500 - loss: 0.8657 - val_accuracy: 0.6929 - val_loss: 1.0427\n",
      "Epoch 715/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.8153 - loss: 0.5127\n",
      "Epoch 715: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 296ms/step - accuracy: 0.8153 - loss: 0.5127 - val_accuracy: 0.6879 - val_loss: 1.0940\n",
      "Epoch 716/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:48\u001b[0m 260ms/step - accuracy: 0.8125 - loss: 0.4310\n",
      "Epoch 716: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8125 - loss: 0.4310 - val_accuracy: 0.6838 - val_loss: 1.0982\n",
      "Epoch 717/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.8098 - loss: 0.5204\n",
      "Epoch 717: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m541s\u001b[0m 300ms/step - accuracy: 0.8098 - loss: 0.5204 - val_accuracy: 0.6879 - val_loss: 1.0814\n",
      "Epoch 718/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:39\u001b[0m 289ms/step - accuracy: 0.6875 - loss: 0.7963\n",
      "Epoch 718: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6875 - loss: 0.7963 - val_accuracy: 0.6872 - val_loss: 1.0841\n",
      "Epoch 719/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.8096 - loss: 0.5138\n",
      "Epoch 719: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 299ms/step - accuracy: 0.8096 - loss: 0.5138 - val_accuracy: 0.6793 - val_loss: 1.1083\n",
      "Epoch 720/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:25\u001b[0m 281ms/step - accuracy: 0.7500 - loss: 0.4324\n",
      "Epoch 720: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7500 - loss: 0.4324 - val_accuracy: 0.6797 - val_loss: 1.1071\n",
      "Epoch 721/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.8060 - loss: 0.5268\n",
      "Epoch 721: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m538s\u001b[0m 299ms/step - accuracy: 0.8060 - loss: 0.5267 - val_accuracy: 0.6952 - val_loss: 1.0548\n",
      "Epoch 722/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:12\u001b[0m 274ms/step - accuracy: 0.9375 - loss: 0.4200\n",
      "Epoch 722: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9375 - loss: 0.4200 - val_accuracy: 0.6950 - val_loss: 1.0549\n",
      "Epoch 723/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.8147 - loss: 0.5126\n",
      "Epoch 723: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 297ms/step - accuracy: 0.8147 - loss: 0.5126 - val_accuracy: 0.6893 - val_loss: 1.0784\n",
      "Epoch 724/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:43\u001b[0m 291ms/step - accuracy: 0.8125 - loss: 0.5239\n",
      "Epoch 724: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8125 - loss: 0.5239 - val_accuracy: 0.6889 - val_loss: 1.0779\n",
      "Epoch 725/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.8145 - loss: 0.5059\n",
      "Epoch 725: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 299ms/step - accuracy: 0.8145 - loss: 0.5059 - val_accuracy: 0.6959 - val_loss: 1.0391\n",
      "Epoch 726/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m7:49\u001b[0m 261ms/step - accuracy: 0.7500 - loss: 0.5253\n",
      "Epoch 726: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7500 - loss: 0.5253 - val_accuracy: 0.6957 - val_loss: 1.0396\n",
      "Epoch 727/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.8180 - loss: 0.5056\n",
      "Epoch 727: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m541s\u001b[0m 300ms/step - accuracy: 0.8180 - loss: 0.5056 - val_accuracy: 0.6903 - val_loss: 1.0590\n",
      "Epoch 728/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:25\u001b[0m 281ms/step - accuracy: 0.8125 - loss: 0.4469\n",
      "Epoch 728: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8125 - loss: 0.4469 - val_accuracy: 0.6893 - val_loss: 1.0623\n",
      "Epoch 729/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.8130 - loss: 0.5145\n",
      "Epoch 729: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m540s\u001b[0m 300ms/step - accuracy: 0.8130 - loss: 0.5145 - val_accuracy: 0.6896 - val_loss: 1.0779\n",
      "Epoch 730/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:21\u001b[0m 279ms/step - accuracy: 0.6250 - loss: 0.6400\n",
      "Epoch 730: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6250 - loss: 0.6400 - val_accuracy: 0.6885 - val_loss: 1.0768\n",
      "Epoch 731/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.8160 - loss: 0.5119\n",
      "Epoch 731: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m538s\u001b[0m 299ms/step - accuracy: 0.8160 - loss: 0.5119 - val_accuracy: 0.6950 - val_loss: 1.0563\n",
      "Epoch 732/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:24\u001b[0m 281ms/step - accuracy: 0.8125 - loss: 0.6016\n",
      "Epoch 732: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8125 - loss: 0.6016 - val_accuracy: 0.6946 - val_loss: 1.0553\n",
      "Epoch 733/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.8114 - loss: 0.5142\n",
      "Epoch 733: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 302ms/step - accuracy: 0.8114 - loss: 0.5142 - val_accuracy: 0.6670 - val_loss: 1.1502\n",
      "Epoch 734/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:20\u001b[0m 278ms/step - accuracy: 0.6250 - loss: 0.8811\n",
      "Epoch 734: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.6250 - loss: 0.8811 - val_accuracy: 0.6689 - val_loss: 1.1449\n",
      "Epoch 735/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.8131 - loss: 0.5099\n",
      "Epoch 735: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 302ms/step - accuracy: 0.8131 - loss: 0.5099 - val_accuracy: 0.6815 - val_loss: 1.1003\n",
      "Epoch 736/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:00\u001b[0m 267ms/step - accuracy: 0.8750 - loss: 0.3128\n",
      "Epoch 736: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8750 - loss: 0.3128 - val_accuracy: 0.6821 - val_loss: 1.0988\n",
      "Epoch 737/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.8179 - loss: 0.4994\n",
      "Epoch 737: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 302ms/step - accuracy: 0.8179 - loss: 0.4994 - val_accuracy: 0.6604 - val_loss: 1.1668\n",
      "Epoch 738/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:29\u001b[0m 283ms/step - accuracy: 0.7500 - loss: 0.6130\n",
      "Epoch 738: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7500 - loss: 0.6130 - val_accuracy: 0.6589 - val_loss: 1.1688\n",
      "Epoch 739/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.8133 - loss: 0.5034\n",
      "Epoch 739: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m541s\u001b[0m 300ms/step - accuracy: 0.8133 - loss: 0.5034 - val_accuracy: 0.6940 - val_loss: 1.0636\n",
      "Epoch 740/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:27\u001b[0m 282ms/step - accuracy: 0.8750 - loss: 0.2398\n",
      "Epoch 740: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.2398 - val_accuracy: 0.6938 - val_loss: 1.0679\n",
      "Epoch 741/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.8163 - loss: 0.5041\n",
      "Epoch 741: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 302ms/step - accuracy: 0.8163 - loss: 0.5041 - val_accuracy: 0.6793 - val_loss: 1.1120\n",
      "Epoch 742/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m9:09\u001b[0m 306ms/step - accuracy: 0.8125 - loss: 0.4478\n",
      "Epoch 742: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8125 - loss: 0.4478 - val_accuracy: 0.6794 - val_loss: 1.1126\n",
      "Epoch 743/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.8176 - loss: 0.4966\n",
      "Epoch 743: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m545s\u001b[0m 303ms/step - accuracy: 0.8176 - loss: 0.4966 - val_accuracy: 0.6925 - val_loss: 1.0791\n",
      "Epoch 744/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:31\u001b[0m 284ms/step - accuracy: 0.8750 - loss: 0.3457\n",
      "Epoch 744: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.3457 - val_accuracy: 0.6923 - val_loss: 1.0798\n",
      "Epoch 745/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.8207 - loss: 0.4908\n",
      "Epoch 745: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 303ms/step - accuracy: 0.8207 - loss: 0.4908 - val_accuracy: 0.6869 - val_loss: 1.0688\n",
      "Epoch 746/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m9:18\u001b[0m 310ms/step - accuracy: 0.7500 - loss: 0.4501\n",
      "Epoch 746: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7500 - loss: 0.4501 - val_accuracy: 0.6862 - val_loss: 1.0705\n",
      "Epoch 747/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.8150 - loss: 0.5025\n",
      "Epoch 747: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 301ms/step - accuracy: 0.8150 - loss: 0.5025 - val_accuracy: 0.6857 - val_loss: 1.1052\n",
      "Epoch 748/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m8:32\u001b[0m 285ms/step - accuracy: 0.8750 - loss: 0.4446\n",
      "Epoch 748: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.4446 - val_accuracy: 0.6858 - val_loss: 1.1067\n",
      "Epoch 749/750\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.8224 - loss: 0.4930\n",
      "Epoch 749: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 303ms/step - accuracy: 0.8224 - loss: 0.4931 - val_accuracy: 0.6866 - val_loss: 1.0880\n",
      "Epoch 750/750\n",
      "\u001b[1m   1/1801\u001b[0m \u001b[37m\u001b[0m \u001b[1m9:27\u001b[0m 315ms/step - accuracy: 0.8750 - loss: 0.3205\n",
      "Epoch 750: val_accuracy did not improve from 0.70526\n",
      "\u001b[1m1801/1801\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8750 - loss: 0.3205 - val_accuracy: 0.6871 - val_loss: 1.0859\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "epochs = 750  # S lng epochs  hun luyn m hnh\n",
    "\n",
    "# To callback  lu trng s tt nht\n",
    "checkpoint = ModelCheckpoint(\"model_weights.keras\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Hun luyn m hnh\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.n // validation_generator.batch_size,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "\n",
    "# Lu ton b m hnh (bao gm kin trc, trng s, optimizer)\n",
    "model.save(\"full_model_notEarlyStopPart2.keras\")  # <-- lu ton b model di nh dng chun mi (.keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29200da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('full_model_notEarlyStopPart2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db4beb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7066 images belonging to 7 classes.\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 155ms/step\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.63      0.58      0.60       960\n",
      "     disgust       0.71      0.69      0.70       111\n",
      "        fear       0.60      0.49      0.54      1018\n",
      "       happy       0.86      0.89      0.87      1825\n",
      "     neutral       0.60      0.69      0.64      1216\n",
      "         sad       0.54      0.57      0.56      1139\n",
      "    surprise       0.82      0.79      0.80       797\n",
      "\n",
      "    accuracy                           0.69      7066\n",
      "   macro avg       0.68      0.67      0.67      7066\n",
      "weighted avg       0.69      0.69      0.69      7066\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#  Bc 0: Load model (nu cha load)\n",
    "# model = load_model(\"duong_dan_toi_model.h5\")  # B comment nu cn\n",
    "\n",
    "#  Bc 1: To li validation_generator\n",
    "val_dir = 'D:/DatasetDoAnCoSO/dataset_emotion/images/validation'  #  Thay ng dn ng\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(56, 56),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "#  Bc 2: D on ton b tp validation\n",
    "y_pred_prob = model.predict(validation_generator, verbose=1)  #  KHNG dng `steps=...`\n",
    "y_pred_class = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "#  Bc 3: Ly nhn tht v in Classification Report\n",
    "y_true = validation_generator.classes\n",
    "target_names = list(validation_generator.class_indices.keys())\n",
    "\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_true, y_pred_class, target_names=target_names))\n",
    "\n",
    "#  Bc 4: V Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred_class)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=target_names,\n",
    "            yticklabels=target_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fac9a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('full_model_notEarlyStop.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d7ceec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7066 images belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m111/111\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 159ms/step\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.58      0.43      0.49       960\n",
      "     disgust       0.60      0.47      0.53       111\n",
      "        fear       0.58      0.20      0.30      1018\n",
      "       happy       0.84      0.85      0.85      1825\n",
      "     neutral       0.49      0.74      0.59      1216\n",
      "         sad       0.50      0.46      0.48      1139\n",
      "    surprise       0.58      0.85      0.69       797\n",
      "\n",
      "    accuracy                           0.61      7066\n",
      "   macro avg       0.60      0.57      0.56      7066\n",
      "weighted avg       0.62      0.61      0.59      7066\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#  Bc 0: Load model (nu cha load)\n",
    "# model = load_model(\"duong_dan_toi_model.h5\")  # B comment nu cn\n",
    "\n",
    "#  Bc 1: To li validation_generator\n",
    "val_dir = 'D:/DatasetDoAnCoSO/dataset_emotion/images/validation'  #  Thay ng dn ng\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(56, 56),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "#  Bc 2: D on ton b tp validation\n",
    "y_pred_prob = model.predict(validation_generator, verbose=1)  #  KHNG dng `steps=...`\n",
    "y_pred_class = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "#  Bc 3: Ly nhn tht v in Classification Report\n",
    "y_true = validation_generator.classes\n",
    "target_names = list(validation_generator.class_indices.keys())\n",
    "\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_true, y_pred_class, target_names=target_names))\n",
    "\n",
    "#  Bc 4: V Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred_class)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=target_names,\n",
    "            yticklabels=target_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
