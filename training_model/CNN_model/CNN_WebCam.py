import cv2
import numpy as np
from tensorflow.keras.models import load_model
import json

# --- Load model v√† th√¥ng tin class ---
model = load_model('D:/model/App_Mobile_Emotion/training_model/CNN_model/full_model_notEarlyStopPart2.keras')


with open('D:/model/App_Mobile_Emotion/training_model/CNN_model/generator_info.json', 'r') as f:
    generator_info = json.load(f)
class_labels = generator_info["train_generator"]["class_labels"]
index_to_class = {i: label for i, label in enumerate(class_labels)}

# --- H√†m ti·ªÅn x·ª≠ l√Ω ·∫£nh khu√¥n m·∫∑t ---
def preprocess_face(gray_img, x, y, w, h):
    face = gray_img[y:y+h, x:x+w]
    face = cv2.equalizeHist(face)  # TƒÉng t∆∞∆°ng ph·∫£n
    face_resized = cv2.resize(face, (56, 56))
    face_normalized = face_resized / 255.0
    return np.expand_dims(face_normalized, axis=(0, -1))  # shape: (1, 56, 56, 1)

# --- Kh·ªüi t·∫°o cascade v√† webcam ---
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
cap = cv2.VideoCapture(0)

if not cap.isOpened():
    print("‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c webcam!")
    exit()

print("üé• Webcam ƒëang ch·∫°y... Nh·∫•n 'q' ƒë·ªÉ tho√°t.")

# --- V√≤ng l·∫∑p ch√≠nh ---
while True:
    ret, frame = cap.read()
    if not ret:
        print("‚ùå L·ªói khi ƒë·ªçc frame!")
        break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(60, 60))

    for (x, y, w, h) in faces:
        face_input = preprocess_face(gray, x, y, w, h)
        predictions = model.predict(face_input, verbose=0)[0]

        # Hi·ªÉn th·ªã x√°c su·∫•t t·ª´ng c·∫£m x√∫c
        for i, prob in enumerate(predictions):
            label = f"{index_to_class[i]}: {prob*100:.2f}%"
            cv2.putText(frame, label, (10, 25 + i * 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)

        # Nh√£n ch√≠nh x√°c nh·∫•t
        best_idx = np.argmax(predictions)
        best_label = f"{index_to_class[best_idx]} ({predictions[best_idx]*100:.1f}%)"
        cv2.rectangle(frame, (x, y), (x+w, y+h), (0,255,0), 2)
        cv2.putText(frame, best_label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,0,0), 2)

    cv2.imshow('Emotion Detection - Press q to quit', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
